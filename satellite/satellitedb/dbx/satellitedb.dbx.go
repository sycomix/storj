// AUTOGENERATED BY gopkg.in/spacemonkeygo/dbx.v1
// DO NOT EDIT.

package satellitedb

import (
	"bytes"
	"context"
	"database/sql"
	"errors"
	"fmt"
	"reflect"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"time"
	"unicode"

	"github.com/lib/pq"

	"github.com/mattn/go-sqlite3"
	"math/rand"
)

// Prevent conditional imports from causing build failures
var _ = strconv.Itoa
var _ = strings.LastIndex
var _ = fmt.Sprint
var _ sync.Mutex

var (
	WrapErr = func(err *Error) error { return err }
	Logger  func(format string, args ...interface{})

	errTooManyRows       = errors.New("too many rows")
	errUnsupportedDriver = errors.New("unsupported driver")
	errEmptyUpdate       = errors.New("empty update")
)

func logError(format string, args ...interface{}) {
	if Logger != nil {
		Logger(format, args...)
	}
}

type ErrorCode int

const (
	ErrorCode_Unknown ErrorCode = iota
	ErrorCode_UnsupportedDriver
	ErrorCode_NoRows
	ErrorCode_TxDone
	ErrorCode_TooManyRows
	ErrorCode_ConstraintViolation
	ErrorCode_EmptyUpdate
)

type Error struct {
	Err         error
	Code        ErrorCode
	Driver      string
	Constraint  string
	QuerySuffix string
}

func (e *Error) Error() string {
	return e.Err.Error()
}

func wrapErr(e *Error) error {
	if WrapErr == nil {
		return e
	}
	return WrapErr(e)
}

func makeErr(err error) error {
	if err == nil {
		return nil
	}
	e := &Error{Err: err}
	switch err {
	case sql.ErrNoRows:
		e.Code = ErrorCode_NoRows
	case sql.ErrTxDone:
		e.Code = ErrorCode_TxDone
	}
	return wrapErr(e)
}

func unsupportedDriver(driver string) error {
	return wrapErr(&Error{
		Err:    errUnsupportedDriver,
		Code:   ErrorCode_UnsupportedDriver,
		Driver: driver,
	})
}

func emptyUpdate() error {
	return wrapErr(&Error{
		Err:  errEmptyUpdate,
		Code: ErrorCode_EmptyUpdate,
	})
}

func tooManyRows(query_suffix string) error {
	return wrapErr(&Error{
		Err:         errTooManyRows,
		Code:        ErrorCode_TooManyRows,
		QuerySuffix: query_suffix,
	})
}

func constraintViolation(err error, constraint string) error {
	return wrapErr(&Error{
		Err:        err,
		Code:       ErrorCode_ConstraintViolation,
		Constraint: constraint,
	})
}

type driver interface {
	Exec(query string, args ...interface{}) (sql.Result, error)
	Query(query string, args ...interface{}) (*sql.Rows, error)
	QueryRow(query string, args ...interface{}) *sql.Row
}

var (
	notAPointer     = errors.New("destination not a pointer")
	lossyConversion = errors.New("lossy conversion")
)

type DB struct {
	*sql.DB
	dbMethods

	Hooks struct {
		Now func() time.Time
	}
}

func Open(driver, source string) (db *DB, err error) {
	var sql_db *sql.DB
	switch driver {
	case "postgres":
		sql_db, err = openpostgres(source)
	case "sqlite3":
		sql_db, err = opensqlite3(source)
	default:
		return nil, unsupportedDriver(driver)
	}
	if err != nil {
		return nil, makeErr(err)
	}
	defer func(sql_db *sql.DB) {
		if err != nil {
			sql_db.Close()
		}
	}(sql_db)

	if err := sql_db.Ping(); err != nil {
		return nil, makeErr(err)
	}

	db = &DB{
		DB: sql_db,
	}
	db.Hooks.Now = time.Now

	switch driver {
	case "postgres":
		db.dbMethods = newpostgres(db)
	case "sqlite3":
		db.dbMethods = newsqlite3(db)
	default:
		return nil, unsupportedDriver(driver)
	}

	return db, nil
}

func (obj *DB) Close() (err error) {
	return obj.makeErr(obj.DB.Close())
}

func (obj *DB) Open(ctx context.Context) (*Tx, error) {
	tx, err := obj.DB.Begin()
	if err != nil {
		return nil, obj.makeErr(err)
	}

	return &Tx{
		Tx:        tx,
		txMethods: obj.wrapTx(tx),
	}, nil
}

func (obj *DB) NewRx() *Rx {
	return &Rx{db: obj}
}

func DeleteAll(ctx context.Context, db *DB) (int64, error) {
	tx, err := db.Open(ctx)
	if err != nil {
		return 0, err
	}
	defer func() {
		if err == nil {
			err = db.makeErr(tx.Commit())
			return
		}

		if err_rollback := tx.Rollback(); err_rollback != nil {
			logError("delete-all: rollback failed: %v", db.makeErr(err_rollback))
		}
	}()
	return tx.deleteAll(ctx)
}

type Tx struct {
	Tx *sql.Tx
	txMethods
}

type dialectTx struct {
	tx *sql.Tx
}

func (tx *dialectTx) Commit() (err error) {
	return makeErr(tx.tx.Commit())
}

func (tx *dialectTx) Rollback() (err error) {
	return makeErr(tx.tx.Rollback())
}

type postgresImpl struct {
	db      *DB
	dialect __sqlbundle_postgres
	driver  driver
}

func (obj *postgresImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *postgresImpl) logStmt(stmt string, args ...interface{}) {
	postgresLogStmt(stmt, args...)
}

func (obj *postgresImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

type postgresDB struct {
	db *DB
	*postgresImpl
}

func newpostgres(db *DB) *postgresDB {
	return &postgresDB{
		db: db,
		postgresImpl: &postgresImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *postgresDB) Schema() string {
	return `CREATE TABLE accounting_raws (
	id bigserial NOT NULL,
	node_id bytea NOT NULL,
	interval_end_time timestamp with time zone NOT NULL,
	data_total double precision NOT NULL,
	data_type integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE accounting_rollups (
	id bigserial NOT NULL,
	node_id bytea NOT NULL,
	start_time timestamp with time zone NOT NULL,
	put_total bigint NOT NULL,
	get_total bigint NOT NULL,
	get_audit_total bigint NOT NULL,
	get_repair_total bigint NOT NULL,
	put_repair_total bigint NOT NULL,
	at_rest_total double precision NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE accounting_timestamps (
	name text NOT NULL,
	value timestamp with time zone NOT NULL,
	PRIMARY KEY ( name )
);
CREATE TABLE bwagreements (
	serialnum text NOT NULL,
	storage_node_id bytea NOT NULL,
	uplink_id bytea NOT NULL,
	action bigint NOT NULL,
	total bigint NOT NULL,
	created_at timestamp with time zone NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( serialnum )
);
CREATE TABLE injuredsegments (
	id bigserial NOT NULL,
	info bytea NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE irreparabledbs (
	segmentpath bytea NOT NULL,
	segmentdetail bytea NOT NULL,
	pieces_lost_count bigint NOT NULL,
	seg_damaged_unix_sec bigint NOT NULL,
	repair_attempt_count bigint NOT NULL,
	PRIMARY KEY ( segmentpath )
);
CREATE TABLE nodes (
	id bytea NOT NULL,
	audit_success_count bigint NOT NULL,
	total_audit_count bigint NOT NULL,
	audit_success_ratio double precision NOT NULL,
	uptime_success_count bigint NOT NULL,
	total_uptime_count bigint NOT NULL,
	uptime_ratio double precision NOT NULL,
	created_at timestamp with time zone NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE overlay_cache_nodes (
	node_id bytea NOT NULL,
	node_type integer NOT NULL,
	address text NOT NULL,
	protocol integer NOT NULL,
	operator_email text NOT NULL,
	operator_wallet text NOT NULL,
	free_bandwidth bigint NOT NULL,
	free_disk bigint NOT NULL,
	latency_90 bigint NOT NULL,
	audit_success_ratio double precision NOT NULL,
	audit_uptime_ratio double precision NOT NULL,
	audit_count bigint NOT NULL,
	audit_success_count bigint NOT NULL,
	uptime_count bigint NOT NULL,
	uptime_success_count bigint NOT NULL,
	PRIMARY KEY ( node_id ),
	UNIQUE ( node_id )
);
CREATE TABLE projects (
	id bytea NOT NULL,
	name text NOT NULL,
	description text NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE uplinkDBs (
	publickey bytea NOT NULL,
	id bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE users (
	id bytea NOT NULL,
	first_name text NOT NULL,
	last_name text NOT NULL,
	email text,
	password_hash bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( email )
);
CREATE TABLE api_keys (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	key bytea NOT NULL,
	name text NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( key ),
	UNIQUE ( name, project_id )
);
CREATE TABLE project_members (
	member_id bytea NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( member_id, project_id )
);`
}

func (obj *postgresDB) wrapTx(tx *sql.Tx) txMethods {
	return &postgresTx{
		dialectTx: dialectTx{tx: tx},
		postgresImpl: &postgresImpl{
			db:     obj.db,
			driver: tx,
		},
	}
}

type postgresTx struct {
	dialectTx
	*postgresImpl
}

func postgresLogStmt(stmt string, args ...interface{}) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type sqlite3Impl struct {
	db      *DB
	dialect __sqlbundle_sqlite3
	driver  driver
}

func (obj *sqlite3Impl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *sqlite3Impl) logStmt(stmt string, args ...interface{}) {
	sqlite3LogStmt(stmt, args...)
}

func (obj *sqlite3Impl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

type sqlite3DB struct {
	db *DB
	*sqlite3Impl
}

func newsqlite3(db *DB) *sqlite3DB {
	return &sqlite3DB{
		db: db,
		sqlite3Impl: &sqlite3Impl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *sqlite3DB) Schema() string {
	return `CREATE TABLE accounting_raws (
	id INTEGER NOT NULL,
	node_id BLOB NOT NULL,
	interval_end_time TIMESTAMP NOT NULL,
	data_total REAL NOT NULL,
	data_type INTEGER NOT NULL,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE accounting_rollups (
	id INTEGER NOT NULL,
	node_id BLOB NOT NULL,
	start_time TIMESTAMP NOT NULL,
	put_total INTEGER NOT NULL,
	get_total INTEGER NOT NULL,
	get_audit_total INTEGER NOT NULL,
	get_repair_total INTEGER NOT NULL,
	put_repair_total INTEGER NOT NULL,
	at_rest_total REAL NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE accounting_timestamps (
	name TEXT NOT NULL,
	value TIMESTAMP NOT NULL,
	PRIMARY KEY ( name )
);
CREATE TABLE bwagreements (
	serialnum TEXT NOT NULL,
	storage_node_id BLOB NOT NULL,
	uplink_id BLOB NOT NULL,
	action INTEGER NOT NULL,
	total INTEGER NOT NULL,
	created_at TIMESTAMP NOT NULL,
	expires_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( serialnum )
);
CREATE TABLE injuredsegments (
	id INTEGER NOT NULL,
	info BLOB NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE irreparabledbs (
	segmentpath BLOB NOT NULL,
	segmentdetail BLOB NOT NULL,
	pieces_lost_count INTEGER NOT NULL,
	seg_damaged_unix_sec INTEGER NOT NULL,
	repair_attempt_count INTEGER NOT NULL,
	PRIMARY KEY ( segmentpath )
);
CREATE TABLE nodes (
	id BLOB NOT NULL,
	audit_success_count INTEGER NOT NULL,
	total_audit_count INTEGER NOT NULL,
	audit_success_ratio REAL NOT NULL,
	uptime_success_count INTEGER NOT NULL,
	total_uptime_count INTEGER NOT NULL,
	uptime_ratio REAL NOT NULL,
	created_at TIMESTAMP NOT NULL,
	updated_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE overlay_cache_nodes (
	node_id BLOB NOT NULL,
	node_type INTEGER NOT NULL,
	address TEXT NOT NULL,
	protocol INTEGER NOT NULL,
	operator_email TEXT NOT NULL,
	operator_wallet TEXT NOT NULL,
	free_bandwidth INTEGER NOT NULL,
	free_disk INTEGER NOT NULL,
	latency_90 INTEGER NOT NULL,
	audit_success_ratio REAL NOT NULL,
	audit_uptime_ratio REAL NOT NULL,
	audit_count INTEGER NOT NULL,
	audit_success_count INTEGER NOT NULL,
	uptime_count INTEGER NOT NULL,
	uptime_success_count INTEGER NOT NULL,
	PRIMARY KEY ( node_id ),
	UNIQUE ( node_id )
);
CREATE TABLE projects (
	id BLOB NOT NULL,
	name TEXT NOT NULL,
	description TEXT NOT NULL,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE uplinkDBs (
	publickey BLOB NOT NULL,
	id BLOB NOT NULL,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id )
);
CREATE TABLE users (
	id BLOB NOT NULL,
	first_name TEXT NOT NULL,
	last_name TEXT NOT NULL,
	email TEXT,
	password_hash BLOB NOT NULL,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( email )
);
CREATE TABLE api_keys (
	id BLOB NOT NULL,
	project_id BLOB NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	key BLOB NOT NULL,
	name TEXT NOT NULL,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( key ),
	UNIQUE ( name, project_id )
);
CREATE TABLE project_members (
	member_id BLOB NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	project_id BLOB NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	created_at TIMESTAMP NOT NULL,
	PRIMARY KEY ( member_id, project_id )
);`
}

func (obj *sqlite3DB) wrapTx(tx *sql.Tx) txMethods {
	return &sqlite3Tx{
		dialectTx: dialectTx{tx: tx},
		sqlite3Impl: &sqlite3Impl{
			db:     obj.db,
			driver: tx,
		},
	}
}

type sqlite3Tx struct {
	dialectTx
	*sqlite3Impl
}

func sqlite3LogStmt(stmt string, args ...interface{}) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pretty []interface{}

func (p pretty) Format(f fmt.State, c rune) {
	fmt.Fprint(f, "[")
nextval:
	for i, val := range p {
		if i > 0 {
			fmt.Fprint(f, ", ")
		}
		rv := reflect.ValueOf(val)
		if rv.Kind() == reflect.Ptr {
			if rv.IsNil() {
				fmt.Fprint(f, "NULL")
				continue
			}
			val = rv.Elem().Interface()
		}
		switch v := val.(type) {
		case string:
			fmt.Fprintf(f, "%q", v)
		case time.Time:
			fmt.Fprintf(f, "%s", v.Format(time.RFC3339Nano))
		case []byte:
			for _, b := range v {
				if !unicode.IsPrint(rune(b)) {
					fmt.Fprintf(f, "%#x", v)
					continue nextval
				}
			}
			fmt.Fprintf(f, "%q", v)
		default:
			fmt.Fprintf(f, "%v", v)
		}
	}
	fmt.Fprint(f, "]")
}

type AccountingRaw struct {
	Id              int64
	NodeId          []byte
	IntervalEndTime time.Time
	DataTotal       float64
	DataType        int
	CreatedAt       time.Time
}

func (AccountingRaw) _Table() string { return "accounting_raws" }

type AccountingRaw_Update_Fields struct {
}

type AccountingRaw_Id_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRaw_Id(v int64) AccountingRaw_Id_Field {
	return AccountingRaw_Id_Field{_set: true, _value: v}
}

func (f AccountingRaw_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_Id_Field) _Column() string { return "id" }

type AccountingRaw_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func AccountingRaw_NodeId(v []byte) AccountingRaw_NodeId_Field {
	return AccountingRaw_NodeId_Field{_set: true, _value: v}
}

func (f AccountingRaw_NodeId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_NodeId_Field) _Column() string { return "node_id" }

type AccountingRaw_IntervalEndTime_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingRaw_IntervalEndTime(v time.Time) AccountingRaw_IntervalEndTime_Field {
	return AccountingRaw_IntervalEndTime_Field{_set: true, _value: v}
}

func (f AccountingRaw_IntervalEndTime_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_IntervalEndTime_Field) _Column() string { return "interval_end_time" }

type AccountingRaw_DataTotal_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func AccountingRaw_DataTotal(v float64) AccountingRaw_DataTotal_Field {
	return AccountingRaw_DataTotal_Field{_set: true, _value: v}
}

func (f AccountingRaw_DataTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_DataTotal_Field) _Column() string { return "data_total" }

type AccountingRaw_DataType_Field struct {
	_set   bool
	_null  bool
	_value int
}

func AccountingRaw_DataType(v int) AccountingRaw_DataType_Field {
	return AccountingRaw_DataType_Field{_set: true, _value: v}
}

func (f AccountingRaw_DataType_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_DataType_Field) _Column() string { return "data_type" }

type AccountingRaw_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingRaw_CreatedAt(v time.Time) AccountingRaw_CreatedAt_Field {
	return AccountingRaw_CreatedAt_Field{_set: true, _value: v}
}

func (f AccountingRaw_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRaw_CreatedAt_Field) _Column() string { return "created_at" }

type AccountingRollup struct {
	Id             int64
	NodeId         []byte
	StartTime      time.Time
	PutTotal       int64
	GetTotal       int64
	GetAuditTotal  int64
	GetRepairTotal int64
	PutRepairTotal int64
	AtRestTotal    float64
}

func (AccountingRollup) _Table() string { return "accounting_rollups" }

type AccountingRollup_Update_Fields struct {
}

type AccountingRollup_Id_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_Id(v int64) AccountingRollup_Id_Field {
	return AccountingRollup_Id_Field{_set: true, _value: v}
}

func (f AccountingRollup_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_Id_Field) _Column() string { return "id" }

type AccountingRollup_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func AccountingRollup_NodeId(v []byte) AccountingRollup_NodeId_Field {
	return AccountingRollup_NodeId_Field{_set: true, _value: v}
}

func (f AccountingRollup_NodeId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_NodeId_Field) _Column() string { return "node_id" }

type AccountingRollup_StartTime_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingRollup_StartTime(v time.Time) AccountingRollup_StartTime_Field {
	return AccountingRollup_StartTime_Field{_set: true, _value: v}
}

func (f AccountingRollup_StartTime_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_StartTime_Field) _Column() string { return "start_time" }

type AccountingRollup_PutTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_PutTotal(v int64) AccountingRollup_PutTotal_Field {
	return AccountingRollup_PutTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_PutTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_PutTotal_Field) _Column() string { return "put_total" }

type AccountingRollup_GetTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetTotal(v int64) AccountingRollup_GetTotal_Field {
	return AccountingRollup_GetTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_GetTotal_Field) _Column() string { return "get_total" }

type AccountingRollup_GetAuditTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetAuditTotal(v int64) AccountingRollup_GetAuditTotal_Field {
	return AccountingRollup_GetAuditTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetAuditTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_GetAuditTotal_Field) _Column() string { return "get_audit_total" }

type AccountingRollup_GetRepairTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetRepairTotal(v int64) AccountingRollup_GetRepairTotal_Field {
	return AccountingRollup_GetRepairTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetRepairTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_GetRepairTotal_Field) _Column() string { return "get_repair_total" }

type AccountingRollup_PutRepairTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_PutRepairTotal(v int64) AccountingRollup_PutRepairTotal_Field {
	return AccountingRollup_PutRepairTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_PutRepairTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_PutRepairTotal_Field) _Column() string { return "put_repair_total" }

type AccountingRollup_AtRestTotal_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func AccountingRollup_AtRestTotal(v float64) AccountingRollup_AtRestTotal_Field {
	return AccountingRollup_AtRestTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_AtRestTotal_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingRollup_AtRestTotal_Field) _Column() string { return "at_rest_total" }

type AccountingTimestamps struct {
	Name  string
	Value time.Time
}

func (AccountingTimestamps) _Table() string { return "accounting_timestamps" }

type AccountingTimestamps_Update_Fields struct {
	Value AccountingTimestamps_Value_Field
}

type AccountingTimestamps_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func AccountingTimestamps_Name(v string) AccountingTimestamps_Name_Field {
	return AccountingTimestamps_Name_Field{_set: true, _value: v}
}

func (f AccountingTimestamps_Name_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingTimestamps_Name_Field) _Column() string { return "name" }

type AccountingTimestamps_Value_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingTimestamps_Value(v time.Time) AccountingTimestamps_Value_Field {
	return AccountingTimestamps_Value_Field{_set: true, _value: v}
}

func (f AccountingTimestamps_Value_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (AccountingTimestamps_Value_Field) _Column() string { return "value" }

type Bwagreement struct {
	Serialnum     string
	StorageNodeId []byte
	UplinkId      []byte
	Action        int64
	Total         int64
	CreatedAt     time.Time
	ExpiresAt     time.Time
}

func (Bwagreement) _Table() string { return "bwagreements" }

type Bwagreement_Update_Fields struct {
}

type Bwagreement_Serialnum_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Bwagreement_Serialnum(v string) Bwagreement_Serialnum_Field {
	return Bwagreement_Serialnum_Field{_set: true, _value: v}
}

func (f Bwagreement_Serialnum_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_Serialnum_Field) _Column() string { return "serialnum" }

type Bwagreement_StorageNodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Bwagreement_StorageNodeId(v []byte) Bwagreement_StorageNodeId_Field {
	return Bwagreement_StorageNodeId_Field{_set: true, _value: v}
}

func (f Bwagreement_StorageNodeId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_StorageNodeId_Field) _Column() string { return "storage_node_id" }

type Bwagreement_UplinkId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Bwagreement_UplinkId(v []byte) Bwagreement_UplinkId_Field {
	return Bwagreement_UplinkId_Field{_set: true, _value: v}
}

func (f Bwagreement_UplinkId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_UplinkId_Field) _Column() string { return "uplink_id" }

type Bwagreement_Action_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Bwagreement_Action(v int64) Bwagreement_Action_Field {
	return Bwagreement_Action_Field{_set: true, _value: v}
}

func (f Bwagreement_Action_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_Action_Field) _Column() string { return "action" }

type Bwagreement_Total_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Bwagreement_Total(v int64) Bwagreement_Total_Field {
	return Bwagreement_Total_Field{_set: true, _value: v}
}

func (f Bwagreement_Total_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_Total_Field) _Column() string { return "total" }

type Bwagreement_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Bwagreement_CreatedAt(v time.Time) Bwagreement_CreatedAt_Field {
	return Bwagreement_CreatedAt_Field{_set: true, _value: v}
}

func (f Bwagreement_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_CreatedAt_Field) _Column() string { return "created_at" }

type Bwagreement_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Bwagreement_ExpiresAt(v time.Time) Bwagreement_ExpiresAt_Field {
	return Bwagreement_ExpiresAt_Field{_set: true, _value: v}
}

func (f Bwagreement_ExpiresAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Bwagreement_ExpiresAt_Field) _Column() string { return "expires_at" }

type Injuredsegment struct {
	Id   int64
	Info []byte
}

func (Injuredsegment) _Table() string { return "injuredsegments" }

type Injuredsegment_Update_Fields struct {
}

type Injuredsegment_Id_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Injuredsegment_Id(v int64) Injuredsegment_Id_Field {
	return Injuredsegment_Id_Field{_set: true, _value: v}
}

func (f Injuredsegment_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Injuredsegment_Id_Field) _Column() string { return "id" }

type Injuredsegment_Info_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Injuredsegment_Info(v []byte) Injuredsegment_Info_Field {
	return Injuredsegment_Info_Field{_set: true, _value: v}
}

func (f Injuredsegment_Info_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Injuredsegment_Info_Field) _Column() string { return "info" }

type Irreparabledb struct {
	Segmentpath        []byte
	Segmentdetail      []byte
	PiecesLostCount    int64
	SegDamagedUnixSec  int64
	RepairAttemptCount int64
}

func (Irreparabledb) _Table() string { return "irreparabledbs" }

type Irreparabledb_Update_Fields struct {
	Segmentdetail      Irreparabledb_Segmentdetail_Field
	PiecesLostCount    Irreparabledb_PiecesLostCount_Field
	SegDamagedUnixSec  Irreparabledb_SegDamagedUnixSec_Field
	RepairAttemptCount Irreparabledb_RepairAttemptCount_Field
}

type Irreparabledb_Segmentpath_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Irreparabledb_Segmentpath(v []byte) Irreparabledb_Segmentpath_Field {
	return Irreparabledb_Segmentpath_Field{_set: true, _value: v}
}

func (f Irreparabledb_Segmentpath_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Irreparabledb_Segmentpath_Field) _Column() string { return "segmentpath" }

type Irreparabledb_Segmentdetail_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Irreparabledb_Segmentdetail(v []byte) Irreparabledb_Segmentdetail_Field {
	return Irreparabledb_Segmentdetail_Field{_set: true, _value: v}
}

func (f Irreparabledb_Segmentdetail_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Irreparabledb_Segmentdetail_Field) _Column() string { return "segmentdetail" }

type Irreparabledb_PiecesLostCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Irreparabledb_PiecesLostCount(v int64) Irreparabledb_PiecesLostCount_Field {
	return Irreparabledb_PiecesLostCount_Field{_set: true, _value: v}
}

func (f Irreparabledb_PiecesLostCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Irreparabledb_PiecesLostCount_Field) _Column() string { return "pieces_lost_count" }

type Irreparabledb_SegDamagedUnixSec_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Irreparabledb_SegDamagedUnixSec(v int64) Irreparabledb_SegDamagedUnixSec_Field {
	return Irreparabledb_SegDamagedUnixSec_Field{_set: true, _value: v}
}

func (f Irreparabledb_SegDamagedUnixSec_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Irreparabledb_SegDamagedUnixSec_Field) _Column() string { return "seg_damaged_unix_sec" }

type Irreparabledb_RepairAttemptCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Irreparabledb_RepairAttemptCount(v int64) Irreparabledb_RepairAttemptCount_Field {
	return Irreparabledb_RepairAttemptCount_Field{_set: true, _value: v}
}

func (f Irreparabledb_RepairAttemptCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Irreparabledb_RepairAttemptCount_Field) _Column() string { return "repair_attempt_count" }

type Node struct {
	Id                 []byte
	AuditSuccessCount  int64
	TotalAuditCount    int64
	AuditSuccessRatio  float64
	UptimeSuccessCount int64
	TotalUptimeCount   int64
	UptimeRatio        float64
	CreatedAt          time.Time
	UpdatedAt          time.Time
}

func (Node) _Table() string { return "nodes" }

type Node_Update_Fields struct {
	AuditSuccessCount  Node_AuditSuccessCount_Field
	TotalAuditCount    Node_TotalAuditCount_Field
	AuditSuccessRatio  Node_AuditSuccessRatio_Field
	UptimeSuccessCount Node_UptimeSuccessCount_Field
	TotalUptimeCount   Node_TotalUptimeCount_Field
	UptimeRatio        Node_UptimeRatio_Field
}

type Node_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Node_Id(v []byte) Node_Id_Field {
	return Node_Id_Field{_set: true, _value: v}
}

func (f Node_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_Id_Field) _Column() string { return "id" }

type Node_AuditSuccessCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_AuditSuccessCount(v int64) Node_AuditSuccessCount_Field {
	return Node_AuditSuccessCount_Field{_set: true, _value: v}
}

func (f Node_AuditSuccessCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_AuditSuccessCount_Field) _Column() string { return "audit_success_count" }

type Node_TotalAuditCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_TotalAuditCount(v int64) Node_TotalAuditCount_Field {
	return Node_TotalAuditCount_Field{_set: true, _value: v}
}

func (f Node_TotalAuditCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_TotalAuditCount_Field) _Column() string { return "total_audit_count" }

type Node_AuditSuccessRatio_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Node_AuditSuccessRatio(v float64) Node_AuditSuccessRatio_Field {
	return Node_AuditSuccessRatio_Field{_set: true, _value: v}
}

func (f Node_AuditSuccessRatio_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_AuditSuccessRatio_Field) _Column() string { return "audit_success_ratio" }

type Node_UptimeSuccessCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_UptimeSuccessCount(v int64) Node_UptimeSuccessCount_Field {
	return Node_UptimeSuccessCount_Field{_set: true, _value: v}
}

func (f Node_UptimeSuccessCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_UptimeSuccessCount_Field) _Column() string { return "uptime_success_count" }

type Node_TotalUptimeCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_TotalUptimeCount(v int64) Node_TotalUptimeCount_Field {
	return Node_TotalUptimeCount_Field{_set: true, _value: v}
}

func (f Node_TotalUptimeCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_TotalUptimeCount_Field) _Column() string { return "total_uptime_count" }

type Node_UptimeRatio_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Node_UptimeRatio(v float64) Node_UptimeRatio_Field {
	return Node_UptimeRatio_Field{_set: true, _value: v}
}

func (f Node_UptimeRatio_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_UptimeRatio_Field) _Column() string { return "uptime_ratio" }

type Node_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_CreatedAt(v time.Time) Node_CreatedAt_Field {
	return Node_CreatedAt_Field{_set: true, _value: v}
}

func (f Node_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_CreatedAt_Field) _Column() string { return "created_at" }

type Node_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_UpdatedAt(v time.Time) Node_UpdatedAt_Field {
	return Node_UpdatedAt_Field{_set: true, _value: v}
}

func (f Node_UpdatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Node_UpdatedAt_Field) _Column() string { return "updated_at" }

type OverlayCacheNode struct {
	NodeId             []byte
	NodeType           int
	Address            string
	Protocol           int
	OperatorEmail      string
	OperatorWallet     string
	FreeBandwidth      int64
	FreeDisk           int64
	Latency90          int64
	AuditSuccessRatio  float64
	AuditUptimeRatio   float64
	AuditCount         int64
	AuditSuccessCount  int64
	UptimeCount        int64
	UptimeSuccessCount int64
}

func (OverlayCacheNode) _Table() string { return "overlay_cache_nodes" }

type OverlayCacheNode_Update_Fields struct {
	Address            OverlayCacheNode_Address_Field
	Protocol           OverlayCacheNode_Protocol_Field
	OperatorEmail      OverlayCacheNode_OperatorEmail_Field
	OperatorWallet     OverlayCacheNode_OperatorWallet_Field
	FreeBandwidth      OverlayCacheNode_FreeBandwidth_Field
	FreeDisk           OverlayCacheNode_FreeDisk_Field
	Latency90          OverlayCacheNode_Latency90_Field
	AuditSuccessRatio  OverlayCacheNode_AuditSuccessRatio_Field
	AuditUptimeRatio   OverlayCacheNode_AuditUptimeRatio_Field
	AuditCount         OverlayCacheNode_AuditCount_Field
	AuditSuccessCount  OverlayCacheNode_AuditSuccessCount_Field
	UptimeCount        OverlayCacheNode_UptimeCount_Field
	UptimeSuccessCount OverlayCacheNode_UptimeSuccessCount_Field
}

type OverlayCacheNode_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OverlayCacheNode_NodeId(v []byte) OverlayCacheNode_NodeId_Field {
	return OverlayCacheNode_NodeId_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_NodeId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_NodeId_Field) _Column() string { return "node_id" }

type OverlayCacheNode_NodeType_Field struct {
	_set   bool
	_null  bool
	_value int
}

func OverlayCacheNode_NodeType(v int) OverlayCacheNode_NodeType_Field {
	return OverlayCacheNode_NodeType_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_NodeType_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_NodeType_Field) _Column() string { return "node_type" }

type OverlayCacheNode_Address_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OverlayCacheNode_Address(v string) OverlayCacheNode_Address_Field {
	return OverlayCacheNode_Address_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_Address_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_Address_Field) _Column() string { return "address" }

type OverlayCacheNode_Protocol_Field struct {
	_set   bool
	_null  bool
	_value int
}

func OverlayCacheNode_Protocol(v int) OverlayCacheNode_Protocol_Field {
	return OverlayCacheNode_Protocol_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_Protocol_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_Protocol_Field) _Column() string { return "protocol" }

type OverlayCacheNode_OperatorEmail_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OverlayCacheNode_OperatorEmail(v string) OverlayCacheNode_OperatorEmail_Field {
	return OverlayCacheNode_OperatorEmail_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_OperatorEmail_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_OperatorEmail_Field) _Column() string { return "operator_email" }

type OverlayCacheNode_OperatorWallet_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OverlayCacheNode_OperatorWallet(v string) OverlayCacheNode_OperatorWallet_Field {
	return OverlayCacheNode_OperatorWallet_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_OperatorWallet_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_OperatorWallet_Field) _Column() string { return "operator_wallet" }

type OverlayCacheNode_FreeBandwidth_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_FreeBandwidth(v int64) OverlayCacheNode_FreeBandwidth_Field {
	return OverlayCacheNode_FreeBandwidth_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_FreeBandwidth_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_FreeBandwidth_Field) _Column() string { return "free_bandwidth" }

type OverlayCacheNode_FreeDisk_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_FreeDisk(v int64) OverlayCacheNode_FreeDisk_Field {
	return OverlayCacheNode_FreeDisk_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_FreeDisk_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_FreeDisk_Field) _Column() string { return "free_disk" }

type OverlayCacheNode_Latency90_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_Latency90(v int64) OverlayCacheNode_Latency90_Field {
	return OverlayCacheNode_Latency90_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_Latency90_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_Latency90_Field) _Column() string { return "latency_90" }

type OverlayCacheNode_AuditSuccessRatio_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func OverlayCacheNode_AuditSuccessRatio(v float64) OverlayCacheNode_AuditSuccessRatio_Field {
	return OverlayCacheNode_AuditSuccessRatio_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_AuditSuccessRatio_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_AuditSuccessRatio_Field) _Column() string { return "audit_success_ratio" }

type OverlayCacheNode_AuditUptimeRatio_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func OverlayCacheNode_AuditUptimeRatio(v float64) OverlayCacheNode_AuditUptimeRatio_Field {
	return OverlayCacheNode_AuditUptimeRatio_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_AuditUptimeRatio_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_AuditUptimeRatio_Field) _Column() string { return "audit_uptime_ratio" }

type OverlayCacheNode_AuditCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_AuditCount(v int64) OverlayCacheNode_AuditCount_Field {
	return OverlayCacheNode_AuditCount_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_AuditCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_AuditCount_Field) _Column() string { return "audit_count" }

type OverlayCacheNode_AuditSuccessCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_AuditSuccessCount(v int64) OverlayCacheNode_AuditSuccessCount_Field {
	return OverlayCacheNode_AuditSuccessCount_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_AuditSuccessCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_AuditSuccessCount_Field) _Column() string { return "audit_success_count" }

type OverlayCacheNode_UptimeCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_UptimeCount(v int64) OverlayCacheNode_UptimeCount_Field {
	return OverlayCacheNode_UptimeCount_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_UptimeCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_UptimeCount_Field) _Column() string { return "uptime_count" }

type OverlayCacheNode_UptimeSuccessCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func OverlayCacheNode_UptimeSuccessCount(v int64) OverlayCacheNode_UptimeSuccessCount_Field {
	return OverlayCacheNode_UptimeSuccessCount_Field{_set: true, _value: v}
}

func (f OverlayCacheNode_UptimeSuccessCount_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (OverlayCacheNode_UptimeSuccessCount_Field) _Column() string { return "uptime_success_count" }

type Project struct {
	Id          []byte
	Name        string
	Description string
	CreatedAt   time.Time
}

func (Project) _Table() string { return "projects" }

type Project_Update_Fields struct {
	Description Project_Description_Field
}

type Project_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_Id(v []byte) Project_Id_Field {
	return Project_Id_Field{_set: true, _value: v}
}

func (f Project_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Project_Id_Field) _Column() string { return "id" }

type Project_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Project_Name(v string) Project_Name_Field {
	return Project_Name_Field{_set: true, _value: v}
}

func (f Project_Name_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Project_Name_Field) _Column() string { return "name" }

type Project_Description_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Project_Description(v string) Project_Description_Field {
	return Project_Description_Field{_set: true, _value: v}
}

func (f Project_Description_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Project_Description_Field) _Column() string { return "description" }

type Project_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Project_CreatedAt(v time.Time) Project_CreatedAt_Field {
	return Project_CreatedAt_Field{_set: true, _value: v}
}

func (f Project_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (Project_CreatedAt_Field) _Column() string { return "created_at" }

type UplinkDB struct {
	Publickey []byte
	Id        []byte
	CreatedAt time.Time
}

func (UplinkDB) _Table() string { return "uplinkDBs" }

type UplinkDB_Update_Fields struct {
}

type UplinkDB_Publickey_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func UplinkDB_Publickey(v []byte) UplinkDB_Publickey_Field {
	return UplinkDB_Publickey_Field{_set: true, _value: v}
}

func (f UplinkDB_Publickey_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (UplinkDB_Publickey_Field) _Column() string { return "publickey" }

type UplinkDB_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func UplinkDB_Id(v []byte) UplinkDB_Id_Field {
	return UplinkDB_Id_Field{_set: true, _value: v}
}

func (f UplinkDB_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (UplinkDB_Id_Field) _Column() string { return "id" }

type UplinkDB_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func UplinkDB_CreatedAt(v time.Time) UplinkDB_CreatedAt_Field {
	return UplinkDB_CreatedAt_Field{_set: true, _value: v}
}

func (f UplinkDB_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (UplinkDB_CreatedAt_Field) _Column() string { return "created_at" }

type User struct {
	Id           []byte
	FirstName    string
	LastName     string
	Email        *string
	PasswordHash []byte
	CreatedAt    time.Time
}

func (User) _Table() string { return "users" }

type User_Create_Fields struct {
	Email User_Email_Field
}

type User_Update_Fields struct {
	FirstName    User_FirstName_Field
	LastName     User_LastName_Field
	Email        User_Email_Field
	PasswordHash User_PasswordHash_Field
}

type User_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func User_Id(v []byte) User_Id_Field {
	return User_Id_Field{_set: true, _value: v}
}

func (f User_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_Id_Field) _Column() string { return "id" }

type User_FirstName_Field struct {
	_set   bool
	_null  bool
	_value string
}

func User_FirstName(v string) User_FirstName_Field {
	return User_FirstName_Field{_set: true, _value: v}
}

func (f User_FirstName_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_FirstName_Field) _Column() string { return "first_name" }

type User_LastName_Field struct {
	_set   bool
	_null  bool
	_value string
}

func User_LastName(v string) User_LastName_Field {
	return User_LastName_Field{_set: true, _value: v}
}

func (f User_LastName_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_LastName_Field) _Column() string { return "last_name" }

type User_Email_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_Email(v string) User_Email_Field {
	return User_Email_Field{_set: true, _value: &v}
}

func User_Email_Raw(v *string) User_Email_Field {
	if v == nil {
		return User_Email_Null()
	}
	return User_Email(*v)
}

func User_Email_Null() User_Email_Field {
	return User_Email_Field{_set: true, _null: true}
}

func (f User_Email_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_Email_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_Email_Field) _Column() string { return "email" }

type User_PasswordHash_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func User_PasswordHash(v []byte) User_PasswordHash_Field {
	return User_PasswordHash_Field{_set: true, _value: v}
}

func (f User_PasswordHash_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_PasswordHash_Field) _Column() string { return "password_hash" }

type User_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func User_CreatedAt(v time.Time) User_CreatedAt_Field {
	return User_CreatedAt_Field{_set: true, _value: v}
}

func (f User_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (User_CreatedAt_Field) _Column() string { return "created_at" }

type ApiKey struct {
	Id        []byte
	ProjectId []byte
	Key       []byte
	Name      string
	CreatedAt time.Time
}

func (ApiKey) _Table() string { return "api_keys" }

type ApiKey_Update_Fields struct {
	Name ApiKey_Name_Field
}

type ApiKey_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_Id(v []byte) ApiKey_Id_Field {
	return ApiKey_Id_Field{_set: true, _value: v}
}

func (f ApiKey_Id_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ApiKey_Id_Field) _Column() string { return "id" }

type ApiKey_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_ProjectId(v []byte) ApiKey_ProjectId_Field {
	return ApiKey_ProjectId_Field{_set: true, _value: v}
}

func (f ApiKey_ProjectId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ApiKey_ProjectId_Field) _Column() string { return "project_id" }

type ApiKey_Key_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_Key(v []byte) ApiKey_Key_Field {
	return ApiKey_Key_Field{_set: true, _value: v}
}

func (f ApiKey_Key_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ApiKey_Key_Field) _Column() string { return "key" }

type ApiKey_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ApiKey_Name(v string) ApiKey_Name_Field {
	return ApiKey_Name_Field{_set: true, _value: v}
}

func (f ApiKey_Name_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ApiKey_Name_Field) _Column() string { return "name" }

type ApiKey_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ApiKey_CreatedAt(v time.Time) ApiKey_CreatedAt_Field {
	return ApiKey_CreatedAt_Field{_set: true, _value: v}
}

func (f ApiKey_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ApiKey_CreatedAt_Field) _Column() string { return "created_at" }

type ProjectMember struct {
	MemberId  []byte
	ProjectId []byte
	CreatedAt time.Time
}

func (ProjectMember) _Table() string { return "project_members" }

type ProjectMember_Update_Fields struct {
}

type ProjectMember_MemberId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectMember_MemberId(v []byte) ProjectMember_MemberId_Field {
	return ProjectMember_MemberId_Field{_set: true, _value: v}
}

func (f ProjectMember_MemberId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ProjectMember_MemberId_Field) _Column() string { return "member_id" }

type ProjectMember_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectMember_ProjectId(v []byte) ProjectMember_ProjectId_Field {
	return ProjectMember_ProjectId_Field{_set: true, _value: v}
}

func (f ProjectMember_ProjectId_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ProjectMember_ProjectId_Field) _Column() string { return "project_id" }

type ProjectMember_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ProjectMember_CreatedAt(v time.Time) ProjectMember_CreatedAt_Field {
	return ProjectMember_CreatedAt_Field{_set: true, _value: v}
}

func (f ProjectMember_CreatedAt_Field) value() interface{} {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func (ProjectMember_CreatedAt_Field) _Column() string { return "created_at" }

func toUTC(t time.Time) time.Time {
	return t.UTC()
}

func toDate(t time.Time) time.Time {
	// keep up the minute portion so that translations between timezones will
	// continue to reflect properly.
	return t.Truncate(time.Minute)
}

//
// runtime support for building sql statements
//

type __sqlbundle_SQL interface {
	Render() string

	private()
}

type __sqlbundle_Dialect interface {
	Rebind(sql string) string
}

type __sqlbundle_RenderOp int

const (
	__sqlbundle_NoFlatten __sqlbundle_RenderOp = iota
	__sqlbundle_NoTerminate
)

func __sqlbundle_Render(dialect __sqlbundle_Dialect, sql __sqlbundle_SQL, ops ...__sqlbundle_RenderOp) string {
	out := sql.Render()

	flatten := true
	terminate := true
	for _, op := range ops {
		switch op {
		case __sqlbundle_NoFlatten:
			flatten = false
		case __sqlbundle_NoTerminate:
			terminate = false
		}
	}

	if flatten {
		out = __sqlbundle_flattenSQL(out)
	}
	if terminate {
		out += ";"
	}

	return dialect.Rebind(out)
}

var __sqlbundle_reSpace = regexp.MustCompile(`\s+`)

func __sqlbundle_flattenSQL(s string) string {
	return strings.TrimSpace(__sqlbundle_reSpace.ReplaceAllString(s, " "))
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_postgres struct{}

func (p __sqlbundle_postgres) Rebind(sql string) string {
	out := make([]byte, 0, len(sql)+10)

	j := 1
	for i := 0; i < len(sql); i++ {
		ch := sql[i]
		if ch != '?' {
			out = append(out, ch)
			continue
		}

		out = append(out, '$')
		out = append(out, strconv.Itoa(j)...)
		j++
	}

	return string(out)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_sqlite3 struct{}

func (s __sqlbundle_sqlite3) Rebind(sql string) string {
	return sql
}

type __sqlbundle_Literal string

func (__sqlbundle_Literal) private() {}

func (l __sqlbundle_Literal) Render() string { return string(l) }

type __sqlbundle_Literals struct {
	Join string
	SQLs []__sqlbundle_SQL
}

func (__sqlbundle_Literals) private() {}

func (l __sqlbundle_Literals) Render() string {
	var out bytes.Buffer

	first := true
	for _, sql := range l.SQLs {
		if sql == nil {
			continue
		}
		if !first {
			out.WriteString(l.Join)
		}
		first = false
		out.WriteString(sql.Render())
	}

	return out.String()
}

type __sqlbundle_Condition struct {
	// set at compile/embed time
	Name  string
	Left  string
	Equal bool
	Right string

	// set at runtime
	Null bool
}

func (*__sqlbundle_Condition) private() {}

func (c *__sqlbundle_Condition) Render() string {

	switch {
	case c.Equal && c.Null:
		return c.Left + " is null"
	case c.Equal && !c.Null:
		return c.Left + " = " + c.Right
	case !c.Equal && c.Null:
		return c.Left + " is not null"
	case !c.Equal && !c.Null:
		return c.Left + " != " + c.Right
	default:
		panic("unhandled case")
	}
}

type __sqlbundle_Hole struct {
	// set at compiile/embed time
	Name string

	// set at runtime
	SQL __sqlbundle_SQL
}

func (*__sqlbundle_Hole) private() {}

func (h *__sqlbundle_Hole) Render() string { return h.SQL.Render() }

//
// end runtime support for building sql statements
//

type Id_Row struct {
	Id []byte
}

type Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row struct {
	Node_Id                         []byte
	Node_CreatedAt                  time.Time
	Node_AuditSuccessRatio          float64
	AccountingRollup_StartTime      time.Time
	AccountingRollup_PutTotal       int64
	AccountingRollup_GetTotal       int64
	AccountingRollup_GetAuditTotal  int64
	AccountingRollup_GetRepairTotal int64
	AccountingRollup_PutRepairTotal int64
	AccountingRollup_AtRestTotal    float64
}

type OperatorWallet_Row struct {
	OperatorWallet string
}

type Value_Row struct {
	Value time.Time
}

func (obj *postgresImpl) Create_Bwagreement(ctx context.Context,
	bwagreement_serialnum Bwagreement_Serialnum_Field,
	bwagreement_storage_node_id Bwagreement_StorageNodeId_Field,
	bwagreement_uplink_id Bwagreement_UplinkId_Field,
	bwagreement_action Bwagreement_Action_Field,
	bwagreement_total Bwagreement_Total_Field,
	bwagreement_expires_at Bwagreement_ExpiresAt_Field) (
	bwagreement *Bwagreement, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__serialnum_val := bwagreement_serialnum.value()
	__storage_node_id_val := bwagreement_storage_node_id.value()
	__uplink_id_val := bwagreement_uplink_id.value()
	__action_val := bwagreement_action.value()
	__total_val := bwagreement_total.value()
	__created_at_val := __now
	__expires_at_val := bwagreement_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO bwagreements ( serialnum, storage_node_id, uplink_id, action, total, created_at, expires_at ) VALUES ( ?, ?, ?, ?, ?, ?, ? ) RETURNING bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __serialnum_val, __storage_node_id_val, __uplink_id_val, __action_val, __total_val, __created_at_val, __expires_at_val)

	bwagreement = &Bwagreement{}
	err = obj.driver.QueryRow(__stmt, __serialnum_val, __storage_node_id_val, __uplink_id_val, __action_val, __total_val, __created_at_val, __expires_at_val).Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bwagreement, nil

}

func (obj *postgresImpl) Create_Irreparabledb(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	irreparabledb_segmentdetail Irreparabledb_Segmentdetail_Field,
	irreparabledb_pieces_lost_count Irreparabledb_PiecesLostCount_Field,
	irreparabledb_seg_damaged_unix_sec Irreparabledb_SegDamagedUnixSec_Field,
	irreparabledb_repair_attempt_count Irreparabledb_RepairAttemptCount_Field) (
	irreparabledb *Irreparabledb, err error) {
	__segmentpath_val := irreparabledb_segmentpath.value()
	__segmentdetail_val := irreparabledb_segmentdetail.value()
	__pieces_lost_count_val := irreparabledb_pieces_lost_count.value()
	__seg_damaged_unix_sec_val := irreparabledb_seg_damaged_unix_sec.value()
	__repair_attempt_count_val := irreparabledb_repair_attempt_count.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO irreparabledbs ( segmentpath, segmentdetail, pieces_lost_count, seg_damaged_unix_sec, repair_attempt_count ) VALUES ( ?, ?, ?, ?, ? ) RETURNING irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __segmentpath_val, __segmentdetail_val, __pieces_lost_count_val, __seg_damaged_unix_sec_val, __repair_attempt_count_val)

	irreparabledb = &Irreparabledb{}
	err = obj.driver.QueryRow(__stmt, __segmentpath_val, __segmentdetail_val, __pieces_lost_count_val, __seg_damaged_unix_sec_val, __repair_attempt_count_val).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil

}

func (obj *postgresImpl) Create_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	accounting_timestamps *AccountingTimestamps, err error) {
	__name_val := accounting_timestamps_name.value()
	__value_val := accounting_timestamps_value.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_timestamps ( name, value ) VALUES ( ?, ? ) RETURNING accounting_timestamps.name, accounting_timestamps.value")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __name_val, __value_val)

	accounting_timestamps = &AccountingTimestamps{}
	err = obj.driver.QueryRow(__stmt, __name_val, __value_val).Scan(&accounting_timestamps.Name, &accounting_timestamps.Value)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_timestamps, nil

}

func (obj *postgresImpl) Create_AccountingRollup(ctx context.Context,
	accounting_rollup_node_id AccountingRollup_NodeId_Field,
	accounting_rollup_start_time AccountingRollup_StartTime_Field,
	accounting_rollup_put_total AccountingRollup_PutTotal_Field,
	accounting_rollup_get_total AccountingRollup_GetTotal_Field,
	accounting_rollup_get_audit_total AccountingRollup_GetAuditTotal_Field,
	accounting_rollup_get_repair_total AccountingRollup_GetRepairTotal_Field,
	accounting_rollup_put_repair_total AccountingRollup_PutRepairTotal_Field,
	accounting_rollup_at_rest_total AccountingRollup_AtRestTotal_Field) (
	accounting_rollup *AccountingRollup, err error) {
	__node_id_val := accounting_rollup_node_id.value()
	__start_time_val := accounting_rollup_start_time.value()
	__put_total_val := accounting_rollup_put_total.value()
	__get_total_val := accounting_rollup_get_total.value()
	__get_audit_total_val := accounting_rollup_get_audit_total.value()
	__get_repair_total_val := accounting_rollup_get_repair_total.value()
	__put_repair_total_val := accounting_rollup_put_repair_total.value()
	__at_rest_total_val := accounting_rollup_at_rest_total.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_rollups ( node_id, start_time, put_total, get_total, get_audit_total, get_repair_total, put_repair_total, at_rest_total ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __start_time_val, __put_total_val, __get_total_val, __get_audit_total_val, __get_repair_total_val, __put_repair_total_val, __at_rest_total_val)

	accounting_rollup = &AccountingRollup{}
	err = obj.driver.QueryRow(__stmt, __node_id_val, __start_time_val, __put_total_val, __get_total_val, __get_audit_total_val, __get_repair_total_val, __put_repair_total_val, __at_rest_total_val).Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_rollup, nil

}

func (obj *postgresImpl) Create_AccountingRaw(ctx context.Context,
	accounting_raw_node_id AccountingRaw_NodeId_Field,
	accounting_raw_interval_end_time AccountingRaw_IntervalEndTime_Field,
	accounting_raw_data_total AccountingRaw_DataTotal_Field,
	accounting_raw_data_type AccountingRaw_DataType_Field) (
	accounting_raw *AccountingRaw, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__node_id_val := accounting_raw_node_id.value()
	__interval_end_time_val := accounting_raw_interval_end_time.value()
	__data_total_val := accounting_raw_data_total.value()
	__data_type_val := accounting_raw_data_type.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_raws ( node_id, interval_end_time, data_total, data_type, created_at ) VALUES ( ?, ?, ?, ?, ? ) RETURNING accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __interval_end_time_val, __data_total_val, __data_type_val, __created_at_val)

	accounting_raw = &AccountingRaw{}
	err = obj.driver.QueryRow(__stmt, __node_id_val, __interval_end_time_val, __data_total_val, __data_type_val, __created_at_val).Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_raw, nil

}

func (obj *postgresImpl) Create_Node(ctx context.Context,
	node_id Node_Id_Field,
	node_audit_success_count Node_AuditSuccessCount_Field,
	node_total_audit_count Node_TotalAuditCount_Field,
	node_audit_success_ratio Node_AuditSuccessRatio_Field,
	node_uptime_success_count Node_UptimeSuccessCount_Field,
	node_total_uptime_count Node_TotalUptimeCount_Field,
	node_uptime_ratio Node_UptimeRatio_Field) (
	node *Node, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := node_id.value()
	__audit_success_count_val := node_audit_success_count.value()
	__total_audit_count_val := node_total_audit_count.value()
	__audit_success_ratio_val := node_audit_success_ratio.value()
	__uptime_success_count_val := node_uptime_success_count.value()
	__total_uptime_count_val := node_total_uptime_count.value()
	__uptime_ratio_val := node_uptime_ratio.value()
	__created_at_val := __now
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO nodes ( id, audit_success_count, total_audit_count, audit_success_ratio, uptime_success_count, total_uptime_count, uptime_ratio, created_at, updated_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __audit_success_count_val, __total_audit_count_val, __audit_success_ratio_val, __uptime_success_count_val, __total_uptime_count_val, __uptime_ratio_val, __created_at_val, __updated_at_val)

	node = &Node{}
	err = obj.driver.QueryRow(__stmt, __id_val, __audit_success_count_val, __total_audit_count_val, __audit_success_ratio_val, __uptime_success_count_val, __total_uptime_count_val, __uptime_ratio_val, __created_at_val, __updated_at_val).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil

}

func (obj *postgresImpl) Create_OverlayCacheNode(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	overlay_cache_node_node_type OverlayCacheNode_NodeType_Field,
	overlay_cache_node_address OverlayCacheNode_Address_Field,
	overlay_cache_node_protocol OverlayCacheNode_Protocol_Field,
	overlay_cache_node_operator_email OverlayCacheNode_OperatorEmail_Field,
	overlay_cache_node_operator_wallet OverlayCacheNode_OperatorWallet_Field,
	overlay_cache_node_free_bandwidth OverlayCacheNode_FreeBandwidth_Field,
	overlay_cache_node_free_disk OverlayCacheNode_FreeDisk_Field,
	overlay_cache_node_latency_90 OverlayCacheNode_Latency90_Field,
	overlay_cache_node_audit_success_ratio OverlayCacheNode_AuditSuccessRatio_Field,
	overlay_cache_node_audit_uptime_ratio OverlayCacheNode_AuditUptimeRatio_Field,
	overlay_cache_node_audit_count OverlayCacheNode_AuditCount_Field,
	overlay_cache_node_audit_success_count OverlayCacheNode_AuditSuccessCount_Field,
	overlay_cache_node_uptime_count OverlayCacheNode_UptimeCount_Field,
	overlay_cache_node_uptime_success_count OverlayCacheNode_UptimeSuccessCount_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {
	__node_id_val := overlay_cache_node_node_id.value()
	__node_type_val := overlay_cache_node_node_type.value()
	__address_val := overlay_cache_node_address.value()
	__protocol_val := overlay_cache_node_protocol.value()
	__operator_email_val := overlay_cache_node_operator_email.value()
	__operator_wallet_val := overlay_cache_node_operator_wallet.value()
	__free_bandwidth_val := overlay_cache_node_free_bandwidth.value()
	__free_disk_val := overlay_cache_node_free_disk.value()
	__latency_90_val := overlay_cache_node_latency_90.value()
	__audit_success_ratio_val := overlay_cache_node_audit_success_ratio.value()
	__audit_uptime_ratio_val := overlay_cache_node_audit_uptime_ratio.value()
	__audit_count_val := overlay_cache_node_audit_count.value()
	__audit_success_count_val := overlay_cache_node_audit_success_count.value()
	__uptime_count_val := overlay_cache_node_uptime_count.value()
	__uptime_success_count_val := overlay_cache_node_uptime_success_count.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO overlay_cache_nodes ( node_id, node_type, address, protocol, operator_email, operator_wallet, free_bandwidth, free_disk, latency_90, audit_success_ratio, audit_uptime_ratio, audit_count, audit_success_count, uptime_count, uptime_success_count ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __node_type_val, __address_val, __protocol_val, __operator_email_val, __operator_wallet_val, __free_bandwidth_val, __free_disk_val, __latency_90_val, __audit_success_ratio_val, __audit_uptime_ratio_val, __audit_count_val, __audit_success_count_val, __uptime_count_val, __uptime_success_count_val)

	overlay_cache_node = &OverlayCacheNode{}
	err = obj.driver.QueryRow(__stmt, __node_id_val, __node_type_val, __address_val, __protocol_val, __operator_email_val, __operator_wallet_val, __free_bandwidth_val, __free_disk_val, __latency_90_val, __audit_success_ratio_val, __audit_uptime_ratio_val, __audit_count_val, __audit_success_count_val, __uptime_count_val, __uptime_success_count_val).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil

}

func (obj *postgresImpl) Create_Injuredsegment(ctx context.Context,
	injuredsegment_info Injuredsegment_Info_Field) (
	injuredsegment *Injuredsegment, err error) {
	__info_val := injuredsegment_info.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO injuredsegments ( info ) VALUES ( ? ) RETURNING injuredsegments.id, injuredsegments.info")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __info_val)

	injuredsegment = &Injuredsegment{}
	err = obj.driver.QueryRow(__stmt, __info_val).Scan(&injuredsegment.Id, &injuredsegment.Info)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return injuredsegment, nil

}

func (obj *postgresImpl) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_first_name User_FirstName_Field,
	user_last_name User_LastName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := user_id.value()
	__first_name_val := user_first_name.value()
	__last_name_val := user_last_name.value()
	__email_val := optional.Email.value()
	__password_hash_val := user_password_hash.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO users ( id, first_name, last_name, email, password_hash, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __first_name_val, __last_name_val, __email_val, __password_hash_val, __created_at_val)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __id_val, __first_name_val, __last_name_val, __email_val, __password_hash_val, __created_at_val).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *postgresImpl) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field) (
	project *Project, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := project_id.value()
	__name_val := project_name.value()
	__description_val := project_description.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO projects ( id, name, description, created_at ) VALUES ( ?, ?, ?, ? ) RETURNING projects.id, projects.name, projects.description, projects.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __name_val, __description_val, __created_at_val)

	project = &Project{}
	err = obj.driver.QueryRow(__stmt, __id_val, __name_val, __description_val, __created_at_val).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *postgresImpl) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__member_id_val := project_member_member_id.value()
	__project_id_val := project_member_project_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO project_members ( member_id, project_id, created_at ) VALUES ( ?, ?, ? ) RETURNING project_members.member_id, project_members.project_id, project_members.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __member_id_val, __project_id_val, __created_at_val)

	project_member = &ProjectMember{}
	err = obj.driver.QueryRow(__stmt, __member_id_val, __project_id_val, __created_at_val).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *postgresImpl) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_key ApiKey_Key_Field,
	api_key_name ApiKey_Name_Field) (
	api_key *ApiKey, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := api_key_id.value()
	__project_id_val := api_key_project_id.value()
	__key_val := api_key_key.value()
	__name_val := api_key_name.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO api_keys ( id, project_id, key, name, created_at ) VALUES ( ?, ?, ?, ?, ? ) RETURNING api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __project_id_val, __key_val, __name_val, __created_at_val)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __id_val, __project_id_val, __key_val, __name_val, __created_at_val).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *postgresImpl) Create_UplinkDB(ctx context.Context,
	uplinkDB_publickey UplinkDB_Publickey_Field,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__publickey_val := uplinkDB_publickey.value()
	__id_val := uplinkDB_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO uplinkDBs ( publickey, id, created_at ) VALUES ( ?, ?, ? ) RETURNING uplinkDBs.publickey, uplinkDBs.id, uplinkDBs.created_at")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __publickey_val, __id_val, __created_at_val)

	uplinkDB = &UplinkDB{}
	err = obj.driver.QueryRow(__stmt, __publickey_val, __id_val, __created_at_val).Scan(&uplinkDB.Publickey, &uplinkDB.Id, &uplinkDB.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return uplinkDB, nil

}

func (obj *postgresImpl) Limited_Bwagreement(ctx context.Context,
	limit int, offset int64) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values)

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) All_Bwagreement(ctx context.Context) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) All_Bwagreement_By_CreatedAt_Greater(ctx context.Context,
	bwagreement_created_at_greater Bwagreement_CreatedAt_Field) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements WHERE bwagreements.created_at > ?")

	var __values []interface{}
	__values = append(__values, bwagreement_created_at_greater.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	irreparabledb *Irreparabledb, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count FROM irreparabledbs WHERE irreparabledbs.segmentpath = ?")

	var __values []interface{}
	__values = append(__values, irreparabledb_segmentpath.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	irreparabledb = &Irreparabledb{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil

}

func (obj *postgresImpl) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __values []interface{}
	__values = append(__values, accounting_timestamps_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Value_Row{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&row.Value)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return row, nil

}

func (obj *postgresImpl) Get_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	accounting_rollup *AccountingRollup, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM accounting_rollups WHERE accounting_rollups.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_rollup = &AccountingRollup{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_rollup, nil

}

func (obj *postgresImpl) All_AccountingRollup_By_StartTime_GreaterOrEqual(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field) (
	rows []*AccountingRollup, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM accounting_rollups WHERE accounting_rollups.start_time >= ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_start_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_rollup := &AccountingRollup{}
		err = __rows.Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_rollup)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	accounting_raw *AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws WHERE accounting_raws.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_raw = &AccountingRaw{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_raw, nil

}

func (obj *postgresImpl) All_AccountingRaw(ctx context.Context) (
	rows []*AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_raw := &AccountingRaw{}
		err = __rows.Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_raw)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) All_AccountingRaw_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	accounting_raw_interval_end_time_greater_or_equal AccountingRaw_IntervalEndTime_Field) (
	rows []*AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws WHERE accounting_raws.interval_end_time >= ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_interval_end_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_raw := &AccountingRaw{}
		err = __rows.Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_raw)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at FROM nodes WHERE nodes.id = ?")

	var __values []interface{}
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil

}

func (obj *postgresImpl) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id FROM nodes")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		row := &Id_Row{}
		err = __rows.Scan(&row.Id)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, row)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) All_Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_By_AccountingRollup_StartTime_GreaterOrEqual_And_AccountingRollup_StartTime_Less_OrderBy_Asc_Node_Id(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field,
	accounting_rollup_start_time_less AccountingRollup_StartTime_Field) (
	rows []*Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.created_at, nodes.audit_success_ratio, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM nodes  JOIN accounting_rollups ON nodes.id = accounting_rollups.node_id WHERE accounting_rollups.start_time >= ? AND accounting_rollups.start_time < ? ORDER BY nodes.id")

	var __values []interface{}
	__values = append(__values, accounting_rollup_start_time_greater_or_equal.value(), accounting_rollup_start_time_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		row := &Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row{}
		err = __rows.Scan(&row.Node_Id, &row.Node_CreatedAt, &row.Node_AuditSuccessRatio, &row.AccountingRollup_StartTime, &row.AccountingRollup_PutTotal, &row.AccountingRollup_GetTotal, &row.AccountingRollup_GetAuditTotal, &row.AccountingRollup_GetRepairTotal, &row.AccountingRollup_PutRepairTotal, &row.AccountingRollup_AtRestTotal)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, row)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	overlay_cache_node = &OverlayCacheNode{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil

}

func (obj *postgresImpl) Get_OverlayCacheNode_OperatorWallet_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	row *OperatorWallet_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.operator_wallet FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &OperatorWallet_Row{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&row.OperatorWallet)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return row, nil

}

func (obj *postgresImpl) Limited_OverlayCacheNode_By_NodeId_GreaterOrEqual(ctx context.Context,
	overlay_cache_node_node_id_greater_or_equal OverlayCacheNode_NodeId_Field,
	limit int, offset int64) (
	rows []*OverlayCacheNode, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id >= ? LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id_greater_or_equal.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		overlay_cache_node := &OverlayCacheNode{}
		err = __rows.Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, overlay_cache_node)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) First_Injuredsegment(ctx context.Context) (
	injuredsegment *Injuredsegment, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT injuredsegments.id, injuredsegments.info FROM injuredsegments LIMIT 1 OFFSET 0")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	if !__rows.Next() {
		if err := __rows.Err(); err != nil {
			return nil, obj.makeErr(err)
		}
		return nil, nil
	}

	injuredsegment = &Injuredsegment{}
	err = __rows.Scan(&injuredsegment.Id, &injuredsegment.Info)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	return injuredsegment, nil

}

func (obj *postgresImpl) Limited_Injuredsegment(ctx context.Context,
	limit int, offset int64) (
	rows []*Injuredsegment, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT injuredsegments.id, injuredsegments.info FROM injuredsegments LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values)

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		injuredsegment := &Injuredsegment{}
		err = __rows.Scan(&injuredsegment.Id, &injuredsegment.Info)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, injuredsegment)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_User_By_Email(ctx context.Context,
	user_email User_Email_Field) (
	user *User, err error) {

	var __cond_0 = &__sqlbundle_Condition{Left: "users.email", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE "), __cond_0}}

	var __values []interface{}
	__values = append(__values)

	if !user_email.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_email.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *postgresImpl) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE users.id = ?")

	var __values []interface{}
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *postgresImpl) All_Project(ctx context.Context) (
	rows []*Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project := &Project{}
		err = __rows.Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects WHERE projects.id = ?")

	var __values []interface{}
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *postgresImpl) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects  JOIN project_members ON projects.id = project_members.project_id WHERE project_members.member_id = ? ORDER BY projects.name")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project := &Project{}
		err = __rows.Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.created_at FROM project_members WHERE project_members.member_id = ?")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project_member := &ProjectMember{}
		err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project_member)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Limited_ProjectMember_By_ProjectId(ctx context.Context,
	project_member_project_id ProjectMember_ProjectId_Field,
	limit int, offset int64) (
	rows []*ProjectMember, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.created_at FROM project_members WHERE project_members.project_id = ? LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values, project_member_project_id.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project_member := &ProjectMember{}
		err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project_member)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	api_key *ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.id = ?")

	var __values []interface{}
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *postgresImpl) Get_ApiKey_By_Key(ctx context.Context,
	api_key_key ApiKey_Key_Field) (
	api_key *ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.key = ?")

	var __values []interface{}
	__values = append(__values, api_key_key.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *postgresImpl) All_ApiKey_By_ProjectId_OrderBy_Asc_Name(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	rows []*ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.project_id = ? ORDER BY api_keys.name")

	var __values []interface{}
	__values = append(__values, api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		api_key := &ApiKey{}
		err = __rows.Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, api_key)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *postgresImpl) Get_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT uplinkDBs.publickey, uplinkDBs.id, uplinkDBs.created_at FROM uplinkDBs WHERE uplinkDBs.id = ?")

	var __values []interface{}
	__values = append(__values, uplinkDB_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	uplinkDB = &UplinkDB{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&uplinkDB.Publickey, &uplinkDB.Id, &uplinkDB.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return uplinkDB, nil

}

func (obj *postgresImpl) Update_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	update Irreparabledb_Update_Fields) (
	irreparabledb *Irreparabledb, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE irreparabledbs SET "), __sets, __sqlbundle_Literal(" WHERE irreparabledbs.segmentpath = ? RETURNING irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Segmentdetail._set {
		__values = append(__values, update.Segmentdetail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("segmentdetail = ?"))
	}

	if update.PiecesLostCount._set {
		__values = append(__values, update.PiecesLostCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("pieces_lost_count = ?"))
	}

	if update.SegDamagedUnixSec._set {
		__values = append(__values, update.SegDamagedUnixSec.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("seg_damaged_unix_sec = ?"))
	}

	if update.RepairAttemptCount._set {
		__values = append(__values, update.RepairAttemptCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("repair_attempt_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, irreparabledb_segmentpath.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	irreparabledb = &Irreparabledb{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil
}

func (obj *postgresImpl) Update_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	accounting_timestamps *AccountingTimestamps, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE accounting_timestamps SET "), __sets, __sqlbundle_Literal(" WHERE accounting_timestamps.name = ? RETURNING accounting_timestamps.name, accounting_timestamps.value")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Value._set {
		__values = append(__values, update.Value.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("value = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, accounting_timestamps_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_timestamps = &AccountingTimestamps{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&accounting_timestamps.Name, &accounting_timestamps.Value)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_timestamps, nil
}

func (obj *postgresImpl) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? RETURNING nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.AuditSuccessRatio._set {
		__values = append(__values, update.AuditSuccessRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_ratio = ?"))
	}

	if update.UptimeSuccessCount._set {
		__values = append(__values, update.UptimeSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_success_count = ?"))
	}

	if update.TotalUptimeCount._set {
		__values = append(__values, update.TotalUptimeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_uptime_count = ?"))
	}

	if update.UptimeRatio._set {
		__values = append(__values, update.UptimeRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_ratio = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil
}

func (obj *postgresImpl) Update_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	update OverlayCacheNode_Update_Fields) (
	overlay_cache_node *OverlayCacheNode, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE overlay_cache_nodes SET "), __sets, __sqlbundle_Literal(" WHERE overlay_cache_nodes.node_id = ? RETURNING overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.OperatorEmail._set {
		__values = append(__values, update.OperatorEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("operator_email = ?"))
	}

	if update.OperatorWallet._set {
		__values = append(__values, update.OperatorWallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("operator_wallet = ?"))
	}

	if update.FreeBandwidth._set {
		__values = append(__values, update.FreeBandwidth.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_bandwidth = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.AuditSuccessRatio._set {
		__values = append(__values, update.AuditSuccessRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_ratio = ?"))
	}

	if update.AuditUptimeRatio._set {
		__values = append(__values, update.AuditUptimeRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_uptime_ratio = ?"))
	}

	if update.AuditCount._set {
		__values = append(__values, update.AuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_count = ?"))
	}

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.UptimeCount._set {
		__values = append(__values, update.UptimeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_count = ?"))
	}

	if update.UptimeSuccessCount._set {
		__values = append(__values, update.UptimeSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_success_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, overlay_cache_node_node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	overlay_cache_node = &OverlayCacheNode{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil
}

func (obj *postgresImpl) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE users SET "), __sets, __sqlbundle_Literal(" WHERE users.id = ? RETURNING users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.FirstName._set {
		__values = append(__values, update.FirstName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("first_name = ?"))
	}

	if update.LastName._set {
		__values = append(__values, update.LastName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_name = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.PasswordHash._set {
		__values = append(__values, update.PasswordHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("password_hash = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil
}

func (obj *postgresImpl) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE projects SET "), __sets, __sqlbundle_Literal(" WHERE projects.id = ? RETURNING projects.id, projects.name, projects.description, projects.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Description._set {
		__values = append(__values, update.Description.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("description = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil
}

func (obj *postgresImpl) Update_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	api_key *ApiKey, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE api_keys SET "), __sets, __sqlbundle_Literal(" WHERE api_keys.id = ? RETURNING api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, api_key_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil
}

func (obj *postgresImpl) Delete_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM irreparabledbs WHERE irreparabledbs.segmentpath = ?")

	var __values []interface{}
	__values = append(__values, irreparabledb_segmentpath.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM accounting_rollups WHERE accounting_rollups.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM accounting_raws WHERE accounting_raws.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM nodes WHERE nodes.id = ?")

	var __values []interface{}
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_Injuredsegment_By_Id(ctx context.Context,
	injuredsegment_id Injuredsegment_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM injuredsegments WHERE injuredsegments.id = ?")

	var __values []interface{}
	__values = append(__values, injuredsegment_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM users WHERE users.id = ?")

	var __values []interface{}
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM projects WHERE projects.id = ?")

	var __values []interface{}
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.id = ?")

	var __values []interface{}
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *postgresImpl) Delete_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM uplinkDBs WHERE uplinkDBs.id = ?")

	var __values []interface{}
	__values = append(__values, uplinkDB_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (impl postgresImpl) isConstraintError(err error) (
	constraint string, ok bool) {
	if e, ok := err.(*pq.Error); ok {
		if e.Code.Class() == "23" {
			return e.Constraint, true
		}
	}
	return "", false
}

func (obj *postgresImpl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.Exec("DELETE FROM project_members;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM users;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM uplinkDBs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM projects;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM overlay_cache_nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM irreparabledbs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM injuredsegments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM bwagreements;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_timestamps;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_raws;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *sqlite3Impl) Create_Bwagreement(ctx context.Context,
	bwagreement_serialnum Bwagreement_Serialnum_Field,
	bwagreement_storage_node_id Bwagreement_StorageNodeId_Field,
	bwagreement_uplink_id Bwagreement_UplinkId_Field,
	bwagreement_action Bwagreement_Action_Field,
	bwagreement_total Bwagreement_Total_Field,
	bwagreement_expires_at Bwagreement_ExpiresAt_Field) (
	bwagreement *Bwagreement, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__serialnum_val := bwagreement_serialnum.value()
	__storage_node_id_val := bwagreement_storage_node_id.value()
	__uplink_id_val := bwagreement_uplink_id.value()
	__action_val := bwagreement_action.value()
	__total_val := bwagreement_total.value()
	__created_at_val := __now
	__expires_at_val := bwagreement_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO bwagreements ( serialnum, storage_node_id, uplink_id, action, total, created_at, expires_at ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __serialnum_val, __storage_node_id_val, __uplink_id_val, __action_val, __total_val, __created_at_val, __expires_at_val)

	__res, err := obj.driver.Exec(__stmt, __serialnum_val, __storage_node_id_val, __uplink_id_val, __action_val, __total_val, __created_at_val, __expires_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastBwagreement(ctx, __pk)

}

func (obj *sqlite3Impl) Create_Irreparabledb(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	irreparabledb_segmentdetail Irreparabledb_Segmentdetail_Field,
	irreparabledb_pieces_lost_count Irreparabledb_PiecesLostCount_Field,
	irreparabledb_seg_damaged_unix_sec Irreparabledb_SegDamagedUnixSec_Field,
	irreparabledb_repair_attempt_count Irreparabledb_RepairAttemptCount_Field) (
	irreparabledb *Irreparabledb, err error) {
	__segmentpath_val := irreparabledb_segmentpath.value()
	__segmentdetail_val := irreparabledb_segmentdetail.value()
	__pieces_lost_count_val := irreparabledb_pieces_lost_count.value()
	__seg_damaged_unix_sec_val := irreparabledb_seg_damaged_unix_sec.value()
	__repair_attempt_count_val := irreparabledb_repair_attempt_count.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO irreparabledbs ( segmentpath, segmentdetail, pieces_lost_count, seg_damaged_unix_sec, repair_attempt_count ) VALUES ( ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __segmentpath_val, __segmentdetail_val, __pieces_lost_count_val, __seg_damaged_unix_sec_val, __repair_attempt_count_val)

	__res, err := obj.driver.Exec(__stmt, __segmentpath_val, __segmentdetail_val, __pieces_lost_count_val, __seg_damaged_unix_sec_val, __repair_attempt_count_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastIrreparabledb(ctx, __pk)

}

func (obj *sqlite3Impl) Create_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	accounting_timestamps *AccountingTimestamps, err error) {
	__name_val := accounting_timestamps_name.value()
	__value_val := accounting_timestamps_value.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_timestamps ( name, value ) VALUES ( ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __name_val, __value_val)

	__res, err := obj.driver.Exec(__stmt, __name_val, __value_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastAccountingTimestamps(ctx, __pk)

}

func (obj *sqlite3Impl) Create_AccountingRollup(ctx context.Context,
	accounting_rollup_node_id AccountingRollup_NodeId_Field,
	accounting_rollup_start_time AccountingRollup_StartTime_Field,
	accounting_rollup_put_total AccountingRollup_PutTotal_Field,
	accounting_rollup_get_total AccountingRollup_GetTotal_Field,
	accounting_rollup_get_audit_total AccountingRollup_GetAuditTotal_Field,
	accounting_rollup_get_repair_total AccountingRollup_GetRepairTotal_Field,
	accounting_rollup_put_repair_total AccountingRollup_PutRepairTotal_Field,
	accounting_rollup_at_rest_total AccountingRollup_AtRestTotal_Field) (
	accounting_rollup *AccountingRollup, err error) {
	__node_id_val := accounting_rollup_node_id.value()
	__start_time_val := accounting_rollup_start_time.value()
	__put_total_val := accounting_rollup_put_total.value()
	__get_total_val := accounting_rollup_get_total.value()
	__get_audit_total_val := accounting_rollup_get_audit_total.value()
	__get_repair_total_val := accounting_rollup_get_repair_total.value()
	__put_repair_total_val := accounting_rollup_put_repair_total.value()
	__at_rest_total_val := accounting_rollup_at_rest_total.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_rollups ( node_id, start_time, put_total, get_total, get_audit_total, get_repair_total, put_repair_total, at_rest_total ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __start_time_val, __put_total_val, __get_total_val, __get_audit_total_val, __get_repair_total_val, __put_repair_total_val, __at_rest_total_val)

	__res, err := obj.driver.Exec(__stmt, __node_id_val, __start_time_val, __put_total_val, __get_total_val, __get_audit_total_val, __get_repair_total_val, __put_repair_total_val, __at_rest_total_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastAccountingRollup(ctx, __pk)

}

func (obj *sqlite3Impl) Create_AccountingRaw(ctx context.Context,
	accounting_raw_node_id AccountingRaw_NodeId_Field,
	accounting_raw_interval_end_time AccountingRaw_IntervalEndTime_Field,
	accounting_raw_data_total AccountingRaw_DataTotal_Field,
	accounting_raw_data_type AccountingRaw_DataType_Field) (
	accounting_raw *AccountingRaw, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__node_id_val := accounting_raw_node_id.value()
	__interval_end_time_val := accounting_raw_interval_end_time.value()
	__data_total_val := accounting_raw_data_total.value()
	__data_type_val := accounting_raw_data_type.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_raws ( node_id, interval_end_time, data_total, data_type, created_at ) VALUES ( ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __interval_end_time_val, __data_total_val, __data_type_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __node_id_val, __interval_end_time_val, __data_total_val, __data_type_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastAccountingRaw(ctx, __pk)

}

func (obj *sqlite3Impl) Create_Node(ctx context.Context,
	node_id Node_Id_Field,
	node_audit_success_count Node_AuditSuccessCount_Field,
	node_total_audit_count Node_TotalAuditCount_Field,
	node_audit_success_ratio Node_AuditSuccessRatio_Field,
	node_uptime_success_count Node_UptimeSuccessCount_Field,
	node_total_uptime_count Node_TotalUptimeCount_Field,
	node_uptime_ratio Node_UptimeRatio_Field) (
	node *Node, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := node_id.value()
	__audit_success_count_val := node_audit_success_count.value()
	__total_audit_count_val := node_total_audit_count.value()
	__audit_success_ratio_val := node_audit_success_ratio.value()
	__uptime_success_count_val := node_uptime_success_count.value()
	__total_uptime_count_val := node_total_uptime_count.value()
	__uptime_ratio_val := node_uptime_ratio.value()
	__created_at_val := __now
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO nodes ( id, audit_success_count, total_audit_count, audit_success_ratio, uptime_success_count, total_uptime_count, uptime_ratio, created_at, updated_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __audit_success_count_val, __total_audit_count_val, __audit_success_ratio_val, __uptime_success_count_val, __total_uptime_count_val, __uptime_ratio_val, __created_at_val, __updated_at_val)

	__res, err := obj.driver.Exec(__stmt, __id_val, __audit_success_count_val, __total_audit_count_val, __audit_success_ratio_val, __uptime_success_count_val, __total_uptime_count_val, __uptime_ratio_val, __created_at_val, __updated_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastNode(ctx, __pk)

}

func (obj *sqlite3Impl) Create_OverlayCacheNode(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	overlay_cache_node_node_type OverlayCacheNode_NodeType_Field,
	overlay_cache_node_address OverlayCacheNode_Address_Field,
	overlay_cache_node_protocol OverlayCacheNode_Protocol_Field,
	overlay_cache_node_operator_email OverlayCacheNode_OperatorEmail_Field,
	overlay_cache_node_operator_wallet OverlayCacheNode_OperatorWallet_Field,
	overlay_cache_node_free_bandwidth OverlayCacheNode_FreeBandwidth_Field,
	overlay_cache_node_free_disk OverlayCacheNode_FreeDisk_Field,
	overlay_cache_node_latency_90 OverlayCacheNode_Latency90_Field,
	overlay_cache_node_audit_success_ratio OverlayCacheNode_AuditSuccessRatio_Field,
	overlay_cache_node_audit_uptime_ratio OverlayCacheNode_AuditUptimeRatio_Field,
	overlay_cache_node_audit_count OverlayCacheNode_AuditCount_Field,
	overlay_cache_node_audit_success_count OverlayCacheNode_AuditSuccessCount_Field,
	overlay_cache_node_uptime_count OverlayCacheNode_UptimeCount_Field,
	overlay_cache_node_uptime_success_count OverlayCacheNode_UptimeSuccessCount_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {
	__node_id_val := overlay_cache_node_node_id.value()
	__node_type_val := overlay_cache_node_node_type.value()
	__address_val := overlay_cache_node_address.value()
	__protocol_val := overlay_cache_node_protocol.value()
	__operator_email_val := overlay_cache_node_operator_email.value()
	__operator_wallet_val := overlay_cache_node_operator_wallet.value()
	__free_bandwidth_val := overlay_cache_node_free_bandwidth.value()
	__free_disk_val := overlay_cache_node_free_disk.value()
	__latency_90_val := overlay_cache_node_latency_90.value()
	__audit_success_ratio_val := overlay_cache_node_audit_success_ratio.value()
	__audit_uptime_ratio_val := overlay_cache_node_audit_uptime_ratio.value()
	__audit_count_val := overlay_cache_node_audit_count.value()
	__audit_success_count_val := overlay_cache_node_audit_success_count.value()
	__uptime_count_val := overlay_cache_node_uptime_count.value()
	__uptime_success_count_val := overlay_cache_node_uptime_success_count.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO overlay_cache_nodes ( node_id, node_type, address, protocol, operator_email, operator_wallet, free_bandwidth, free_disk, latency_90, audit_success_ratio, audit_uptime_ratio, audit_count, audit_success_count, uptime_count, uptime_success_count ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __node_id_val, __node_type_val, __address_val, __protocol_val, __operator_email_val, __operator_wallet_val, __free_bandwidth_val, __free_disk_val, __latency_90_val, __audit_success_ratio_val, __audit_uptime_ratio_val, __audit_count_val, __audit_success_count_val, __uptime_count_val, __uptime_success_count_val)

	__res, err := obj.driver.Exec(__stmt, __node_id_val, __node_type_val, __address_val, __protocol_val, __operator_email_val, __operator_wallet_val, __free_bandwidth_val, __free_disk_val, __latency_90_val, __audit_success_ratio_val, __audit_uptime_ratio_val, __audit_count_val, __audit_success_count_val, __uptime_count_val, __uptime_success_count_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastOverlayCacheNode(ctx, __pk)

}

func (obj *sqlite3Impl) Create_Injuredsegment(ctx context.Context,
	injuredsegment_info Injuredsegment_Info_Field) (
	injuredsegment *Injuredsegment, err error) {
	__info_val := injuredsegment_info.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO injuredsegments ( info ) VALUES ( ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __info_val)

	__res, err := obj.driver.Exec(__stmt, __info_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastInjuredsegment(ctx, __pk)

}

func (obj *sqlite3Impl) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_first_name User_FirstName_Field,
	user_last_name User_LastName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := user_id.value()
	__first_name_val := user_first_name.value()
	__last_name_val := user_last_name.value()
	__email_val := optional.Email.value()
	__password_hash_val := user_password_hash.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO users ( id, first_name, last_name, email, password_hash, created_at ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __first_name_val, __last_name_val, __email_val, __password_hash_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __id_val, __first_name_val, __last_name_val, __email_val, __password_hash_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastUser(ctx, __pk)

}

func (obj *sqlite3Impl) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field) (
	project *Project, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := project_id.value()
	__name_val := project_name.value()
	__description_val := project_description.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO projects ( id, name, description, created_at ) VALUES ( ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __name_val, __description_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __id_val, __name_val, __description_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastProject(ctx, __pk)

}

func (obj *sqlite3Impl) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__member_id_val := project_member_member_id.value()
	__project_id_val := project_member_project_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO project_members ( member_id, project_id, created_at ) VALUES ( ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __member_id_val, __project_id_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __member_id_val, __project_id_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastProjectMember(ctx, __pk)

}

func (obj *sqlite3Impl) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_key ApiKey_Key_Field,
	api_key_name ApiKey_Name_Field) (
	api_key *ApiKey, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__id_val := api_key_id.value()
	__project_id_val := api_key_project_id.value()
	__key_val := api_key_key.value()
	__name_val := api_key_name.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO api_keys ( id, project_id, key, name, created_at ) VALUES ( ?, ?, ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __id_val, __project_id_val, __key_val, __name_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __id_val, __project_id_val, __key_val, __name_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastApiKey(ctx, __pk)

}

func (obj *sqlite3Impl) Create_UplinkDB(ctx context.Context,
	uplinkDB_publickey UplinkDB_Publickey_Field,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {

	__now := obj.db.Hooks.Now().UTC()
	__publickey_val := uplinkDB_publickey.value()
	__id_val := uplinkDB_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO uplinkDBs ( publickey, id, created_at ) VALUES ( ?, ?, ? )")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __publickey_val, __id_val, __created_at_val)

	__res, err := obj.driver.Exec(__stmt, __publickey_val, __id_val, __created_at_val)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	__pk, err := __res.LastInsertId()
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return obj.getLastUplinkDB(ctx, __pk)

}

func (obj *sqlite3Impl) Limited_Bwagreement(ctx context.Context,
	limit int, offset int64) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values)

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) All_Bwagreement(ctx context.Context) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) All_Bwagreement_By_CreatedAt_Greater(ctx context.Context,
	bwagreement_created_at_greater Bwagreement_CreatedAt_Field) (
	rows []*Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements WHERE bwagreements.created_at > ?")

	var __values []interface{}
	__values = append(__values, bwagreement_created_at_greater.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		bwagreement := &Bwagreement{}
		err = __rows.Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, bwagreement)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	irreparabledb *Irreparabledb, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count FROM irreparabledbs WHERE irreparabledbs.segmentpath = ?")

	var __values []interface{}
	__values = append(__values, irreparabledb_segmentpath.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	irreparabledb = &Irreparabledb{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil

}

func (obj *sqlite3Impl) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __values []interface{}
	__values = append(__values, accounting_timestamps_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Value_Row{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&row.Value)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return row, nil

}

func (obj *sqlite3Impl) Get_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	accounting_rollup *AccountingRollup, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM accounting_rollups WHERE accounting_rollups.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_rollup = &AccountingRollup{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_rollup, nil

}

func (obj *sqlite3Impl) All_AccountingRollup_By_StartTime_GreaterOrEqual(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field) (
	rows []*AccountingRollup, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM accounting_rollups WHERE accounting_rollups.start_time >= ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_start_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_rollup := &AccountingRollup{}
		err = __rows.Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_rollup)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	accounting_raw *AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws WHERE accounting_raws.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_raw = &AccountingRaw{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_raw, nil

}

func (obj *sqlite3Impl) All_AccountingRaw(ctx context.Context) (
	rows []*AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_raw := &AccountingRaw{}
		err = __rows.Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_raw)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) All_AccountingRaw_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	accounting_raw_interval_end_time_greater_or_equal AccountingRaw_IntervalEndTime_Field) (
	rows []*AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws WHERE accounting_raws.interval_end_time >= ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_interval_end_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		accounting_raw := &AccountingRaw{}
		err = __rows.Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, accounting_raw)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at FROM nodes WHERE nodes.id = ?")

	var __values []interface{}
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil

}

func (obj *sqlite3Impl) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id FROM nodes")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		row := &Id_Row{}
		err = __rows.Scan(&row.Id)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, row)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) All_Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_By_AccountingRollup_StartTime_GreaterOrEqual_And_AccountingRollup_StartTime_Less_OrderBy_Asc_Node_Id(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field,
	accounting_rollup_start_time_less AccountingRollup_StartTime_Field) (
	rows []*Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.created_at, nodes.audit_success_ratio, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM nodes  JOIN accounting_rollups ON nodes.id = accounting_rollups.node_id WHERE accounting_rollups.start_time >= ? AND accounting_rollups.start_time < ? ORDER BY nodes.id")

	var __values []interface{}
	__values = append(__values, accounting_rollup_start_time_greater_or_equal.value(), accounting_rollup_start_time_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		row := &Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row{}
		err = __rows.Scan(&row.Node_Id, &row.Node_CreatedAt, &row.Node_AuditSuccessRatio, &row.AccountingRollup_StartTime, &row.AccountingRollup_PutTotal, &row.AccountingRollup_GetTotal, &row.AccountingRollup_GetAuditTotal, &row.AccountingRollup_GetRepairTotal, &row.AccountingRollup_PutRepairTotal, &row.AccountingRollup_AtRestTotal)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, row)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	overlay_cache_node = &OverlayCacheNode{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil

}

func (obj *sqlite3Impl) Get_OverlayCacheNode_OperatorWallet_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	row *OperatorWallet_Row, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.operator_wallet FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &OperatorWallet_Row{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&row.OperatorWallet)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return row, nil

}

func (obj *sqlite3Impl) Limited_OverlayCacheNode_By_NodeId_GreaterOrEqual(ctx context.Context,
	overlay_cache_node_node_id_greater_or_equal OverlayCacheNode_NodeId_Field,
	limit int, offset int64) (
	rows []*OverlayCacheNode, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id >= ? LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id_greater_or_equal.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		overlay_cache_node := &OverlayCacheNode{}
		err = __rows.Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, overlay_cache_node)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) First_Injuredsegment(ctx context.Context) (
	injuredsegment *Injuredsegment, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT injuredsegments.id, injuredsegments.info FROM injuredsegments LIMIT 1 OFFSET 0")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	if !__rows.Next() {
		if err := __rows.Err(); err != nil {
			return nil, obj.makeErr(err)
		}
		return nil, nil
	}

	injuredsegment = &Injuredsegment{}
	err = __rows.Scan(&injuredsegment.Id, &injuredsegment.Info)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	return injuredsegment, nil

}

func (obj *sqlite3Impl) Limited_Injuredsegment(ctx context.Context,
	limit int, offset int64) (
	rows []*Injuredsegment, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT injuredsegments.id, injuredsegments.info FROM injuredsegments LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values)

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		injuredsegment := &Injuredsegment{}
		err = __rows.Scan(&injuredsegment.Id, &injuredsegment.Info)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, injuredsegment)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_User_By_Email(ctx context.Context,
	user_email User_Email_Field) (
	user *User, err error) {

	var __cond_0 = &__sqlbundle_Condition{Left: "users.email", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE "), __cond_0}}

	var __values []interface{}
	__values = append(__values)

	if !user_email.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_email.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *sqlite3Impl) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE users.id = ?")

	var __values []interface{}
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *sqlite3Impl) All_Project(ctx context.Context) (
	rows []*Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects")

	var __values []interface{}
	__values = append(__values)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project := &Project{}
		err = __rows.Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects WHERE projects.id = ?")

	var __values []interface{}
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *sqlite3Impl) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects  JOIN project_members ON projects.id = project_members.project_id WHERE project_members.member_id = ? ORDER BY projects.name")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project := &Project{}
		err = __rows.Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.created_at FROM project_members WHERE project_members.member_id = ?")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project_member := &ProjectMember{}
		err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project_member)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Limited_ProjectMember_By_ProjectId(ctx context.Context,
	project_member_project_id ProjectMember_ProjectId_Field,
	limit int, offset int64) (
	rows []*ProjectMember, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.created_at FROM project_members WHERE project_members.project_id = ? LIMIT ? OFFSET ?")

	var __values []interface{}
	__values = append(__values, project_member_project_id.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		project_member := &ProjectMember{}
		err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, project_member)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	api_key *ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.id = ?")

	var __values []interface{}
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *sqlite3Impl) Get_ApiKey_By_Key(ctx context.Context,
	api_key_key ApiKey_Key_Field) (
	api_key *ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.key = ?")

	var __values []interface{}
	__values = append(__values, api_key_key.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *sqlite3Impl) All_ApiKey_By_ProjectId_OrderBy_Asc_Name(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	rows []*ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.project_id = ? ORDER BY api_keys.name")

	var __values []interface{}
	__values = append(__values, api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__rows, err := obj.driver.Query(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	defer __rows.Close()

	for __rows.Next() {
		api_key := &ApiKey{}
		err = __rows.Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
		if err != nil {
			return nil, obj.makeErr(err)
		}
		rows = append(rows, api_key)
	}
	if err := __rows.Err(); err != nil {
		return nil, obj.makeErr(err)
	}
	return rows, nil

}

func (obj *sqlite3Impl) Get_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT uplinkDBs.publickey, uplinkDBs.id, uplinkDBs.created_at FROM uplinkDBs WHERE uplinkDBs.id = ?")

	var __values []interface{}
	__values = append(__values, uplinkDB_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	uplinkDB = &UplinkDB{}
	err = obj.driver.QueryRow(__stmt, __values...).Scan(&uplinkDB.Publickey, &uplinkDB.Id, &uplinkDB.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return uplinkDB, nil

}

func (obj *sqlite3Impl) Update_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	update Irreparabledb_Update_Fields) (
	irreparabledb *Irreparabledb, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE irreparabledbs SET "), __sets, __sqlbundle_Literal(" WHERE irreparabledbs.segmentpath = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Segmentdetail._set {
		__values = append(__values, update.Segmentdetail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("segmentdetail = ?"))
	}

	if update.PiecesLostCount._set {
		__values = append(__values, update.PiecesLostCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("pieces_lost_count = ?"))
	}

	if update.SegDamagedUnixSec._set {
		__values = append(__values, update.SegDamagedUnixSec.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("seg_damaged_unix_sec = ?"))
	}

	if update.RepairAttemptCount._set {
		__values = append(__values, update.RepairAttemptCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("repair_attempt_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, irreparabledb_segmentpath.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	irreparabledb = &Irreparabledb{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count FROM irreparabledbs WHERE irreparabledbs.segmentpath = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil
}

func (obj *sqlite3Impl) Update_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	accounting_timestamps *AccountingTimestamps, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE accounting_timestamps SET "), __sets, __sqlbundle_Literal(" WHERE accounting_timestamps.name = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Value._set {
		__values = append(__values, update.Value.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("value = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, accounting_timestamps_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	accounting_timestamps = &AccountingTimestamps{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT accounting_timestamps.name, accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&accounting_timestamps.Name, &accounting_timestamps.Value)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_timestamps, nil
}

func (obj *sqlite3Impl) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.AuditSuccessRatio._set {
		__values = append(__values, update.AuditSuccessRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_ratio = ?"))
	}

	if update.UptimeSuccessCount._set {
		__values = append(__values, update.UptimeSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_success_count = ?"))
	}

	if update.TotalUptimeCount._set {
		__values = append(__values, update.TotalUptimeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_uptime_count = ?"))
	}

	if update.UptimeRatio._set {
		__values = append(__values, update.UptimeRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_ratio = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at FROM nodes WHERE nodes.id = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil
}

func (obj *sqlite3Impl) Update_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	update OverlayCacheNode_Update_Fields) (
	overlay_cache_node *OverlayCacheNode, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE overlay_cache_nodes SET "), __sets, __sqlbundle_Literal(" WHERE overlay_cache_nodes.node_id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.OperatorEmail._set {
		__values = append(__values, update.OperatorEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("operator_email = ?"))
	}

	if update.OperatorWallet._set {
		__values = append(__values, update.OperatorWallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("operator_wallet = ?"))
	}

	if update.FreeBandwidth._set {
		__values = append(__values, update.FreeBandwidth.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_bandwidth = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.AuditSuccessRatio._set {
		__values = append(__values, update.AuditSuccessRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_ratio = ?"))
	}

	if update.AuditUptimeRatio._set {
		__values = append(__values, update.AuditUptimeRatio.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_uptime_ratio = ?"))
	}

	if update.AuditCount._set {
		__values = append(__values, update.AuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_count = ?"))
	}

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.UptimeCount._set {
		__values = append(__values, update.UptimeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_count = ?"))
	}

	if update.UptimeSuccessCount._set {
		__values = append(__values, update.UptimeSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("uptime_success_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, overlay_cache_node_node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	overlay_cache_node = &OverlayCacheNode{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil
}

func (obj *sqlite3Impl) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE users SET "), __sets, __sqlbundle_Literal(" WHERE users.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.FirstName._set {
		__values = append(__values, update.FirstName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("first_name = ?"))
	}

	if update.LastName._set {
		__values = append(__values, update.LastName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_name = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.PasswordHash._set {
		__values = append(__values, update.PasswordHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("password_hash = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE users.id = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil
}

func (obj *sqlite3Impl) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE projects SET "), __sets, __sqlbundle_Literal(" WHERE projects.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Description._set {
		__values = append(__values, update.Description.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("description = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects WHERE projects.id = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil
}

func (obj *sqlite3Impl) Update_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	api_key *ApiKey, err error) {
	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE api_keys SET "), __sets, __sqlbundle_Literal(" WHERE api_keys.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []interface{}
	var __args []interface{}

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, api_key_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	_, err = obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	var __embed_stmt_get = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE api_keys.id = ?")

	var __stmt_get = __sqlbundle_Render(obj.dialect, __embed_stmt_get)
	obj.logStmt("(IMPLIED) "+__stmt_get, __args...)

	err = obj.driver.QueryRow(__stmt_get, __args...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil
}

func (obj *sqlite3Impl) Delete_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM irreparabledbs WHERE irreparabledbs.segmentpath = ?")

	var __values []interface{}
	__values = append(__values, irreparabledb_segmentpath.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM accounting_rollups WHERE accounting_rollups.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_rollup_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM accounting_raws WHERE accounting_raws.id = ?")

	var __values []interface{}
	__values = append(__values, accounting_raw_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM nodes WHERE nodes.id = ?")

	var __values []interface{}
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM overlay_cache_nodes WHERE overlay_cache_nodes.node_id = ?")

	var __values []interface{}
	__values = append(__values, overlay_cache_node_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_Injuredsegment_By_Id(ctx context.Context,
	injuredsegment_id Injuredsegment_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM injuredsegments WHERE injuredsegments.id = ?")

	var __values []interface{}
	__values = append(__values, injuredsegment_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM users WHERE users.id = ?")

	var __values []interface{}
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM projects WHERE projects.id = ?")

	var __values []interface{}
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []interface{}
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.id = ?")

	var __values []interface{}
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) Delete_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	deleted bool, err error) {

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM uplinkDBs WHERE uplinkDBs.id = ?")

	var __values []interface{}
	__values = append(__values, uplinkDB_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.Exec(__stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *sqlite3Impl) getLastBwagreement(ctx context.Context,
	pk int64) (
	bwagreement *Bwagreement, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT bwagreements.serialnum, bwagreements.storage_node_id, bwagreements.uplink_id, bwagreements.action, bwagreements.total, bwagreements.created_at, bwagreements.expires_at FROM bwagreements WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	bwagreement = &Bwagreement{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&bwagreement.Serialnum, &bwagreement.StorageNodeId, &bwagreement.UplinkId, &bwagreement.Action, &bwagreement.Total, &bwagreement.CreatedAt, &bwagreement.ExpiresAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bwagreement, nil

}

func (obj *sqlite3Impl) getLastIrreparabledb(ctx context.Context,
	pk int64) (
	irreparabledb *Irreparabledb, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT irreparabledbs.segmentpath, irreparabledbs.segmentdetail, irreparabledbs.pieces_lost_count, irreparabledbs.seg_damaged_unix_sec, irreparabledbs.repair_attempt_count FROM irreparabledbs WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	irreparabledb = &Irreparabledb{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&irreparabledb.Segmentpath, &irreparabledb.Segmentdetail, &irreparabledb.PiecesLostCount, &irreparabledb.SegDamagedUnixSec, &irreparabledb.RepairAttemptCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return irreparabledb, nil

}

func (obj *sqlite3Impl) getLastAccountingTimestamps(ctx context.Context,
	pk int64) (
	accounting_timestamps *AccountingTimestamps, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.name, accounting_timestamps.value FROM accounting_timestamps WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	accounting_timestamps = &AccountingTimestamps{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&accounting_timestamps.Name, &accounting_timestamps.Value)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_timestamps, nil

}

func (obj *sqlite3Impl) getLastAccountingRollup(ctx context.Context,
	pk int64) (
	accounting_rollup *AccountingRollup, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_rollups.id, accounting_rollups.node_id, accounting_rollups.start_time, accounting_rollups.put_total, accounting_rollups.get_total, accounting_rollups.get_audit_total, accounting_rollups.get_repair_total, accounting_rollups.put_repair_total, accounting_rollups.at_rest_total FROM accounting_rollups WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	accounting_rollup = &AccountingRollup{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&accounting_rollup.Id, &accounting_rollup.NodeId, &accounting_rollup.StartTime, &accounting_rollup.PutTotal, &accounting_rollup.GetTotal, &accounting_rollup.GetAuditTotal, &accounting_rollup.GetRepairTotal, &accounting_rollup.PutRepairTotal, &accounting_rollup.AtRestTotal)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_rollup, nil

}

func (obj *sqlite3Impl) getLastAccountingRaw(ctx context.Context,
	pk int64) (
	accounting_raw *AccountingRaw, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_raws.id, accounting_raws.node_id, accounting_raws.interval_end_time, accounting_raws.data_total, accounting_raws.data_type, accounting_raws.created_at FROM accounting_raws WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	accounting_raw = &AccountingRaw{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&accounting_raw.Id, &accounting_raw.NodeId, &accounting_raw.IntervalEndTime, &accounting_raw.DataTotal, &accounting_raw.DataType, &accounting_raw.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return accounting_raw, nil

}

func (obj *sqlite3Impl) getLastNode(ctx context.Context,
	pk int64) (
	node *Node, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.audit_success_count, nodes.total_audit_count, nodes.audit_success_ratio, nodes.uptime_success_count, nodes.total_uptime_count, nodes.uptime_ratio, nodes.created_at, nodes.updated_at FROM nodes WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	node = &Node{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&node.Id, &node.AuditSuccessCount, &node.TotalAuditCount, &node.AuditSuccessRatio, &node.UptimeSuccessCount, &node.TotalUptimeCount, &node.UptimeRatio, &node.CreatedAt, &node.UpdatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil

}

func (obj *sqlite3Impl) getLastOverlayCacheNode(ctx context.Context,
	pk int64) (
	overlay_cache_node *OverlayCacheNode, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT overlay_cache_nodes.node_id, overlay_cache_nodes.node_type, overlay_cache_nodes.address, overlay_cache_nodes.protocol, overlay_cache_nodes.operator_email, overlay_cache_nodes.operator_wallet, overlay_cache_nodes.free_bandwidth, overlay_cache_nodes.free_disk, overlay_cache_nodes.latency_90, overlay_cache_nodes.audit_success_ratio, overlay_cache_nodes.audit_uptime_ratio, overlay_cache_nodes.audit_count, overlay_cache_nodes.audit_success_count, overlay_cache_nodes.uptime_count, overlay_cache_nodes.uptime_success_count FROM overlay_cache_nodes WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	overlay_cache_node = &OverlayCacheNode{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&overlay_cache_node.NodeId, &overlay_cache_node.NodeType, &overlay_cache_node.Address, &overlay_cache_node.Protocol, &overlay_cache_node.OperatorEmail, &overlay_cache_node.OperatorWallet, &overlay_cache_node.FreeBandwidth, &overlay_cache_node.FreeDisk, &overlay_cache_node.Latency90, &overlay_cache_node.AuditSuccessRatio, &overlay_cache_node.AuditUptimeRatio, &overlay_cache_node.AuditCount, &overlay_cache_node.AuditSuccessCount, &overlay_cache_node.UptimeCount, &overlay_cache_node.UptimeSuccessCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return overlay_cache_node, nil

}

func (obj *sqlite3Impl) getLastInjuredsegment(ctx context.Context,
	pk int64) (
	injuredsegment *Injuredsegment, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT injuredsegments.id, injuredsegments.info FROM injuredsegments WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	injuredsegment = &Injuredsegment{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&injuredsegment.Id, &injuredsegment.Info)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return injuredsegment, nil

}

func (obj *sqlite3Impl) getLastUser(ctx context.Context,
	pk int64) (
	user *User, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.first_name, users.last_name, users.email, users.password_hash, users.created_at FROM users WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	user = &User{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&user.Id, &user.FirstName, &user.LastName, &user.Email, &user.PasswordHash, &user.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *sqlite3Impl) getLastProject(ctx context.Context,
	pk int64) (
	project *Project, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.name, projects.description, projects.created_at FROM projects WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	project = &Project{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&project.Id, &project.Name, &project.Description, &project.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *sqlite3Impl) getLastProjectMember(ctx context.Context,
	pk int64) (
	project_member *ProjectMember, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.created_at FROM project_members WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	project_member = &ProjectMember{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *sqlite3Impl) getLastApiKey(ctx context.Context,
	pk int64) (
	api_key *ApiKey, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.key, api_keys.name, api_keys.created_at FROM api_keys WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	api_key = &ApiKey{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Key, &api_key.Name, &api_key.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *sqlite3Impl) getLastUplinkDB(ctx context.Context,
	pk int64) (
	uplinkDB *UplinkDB, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT uplinkDBs.publickey, uplinkDBs.id, uplinkDBs.created_at FROM uplinkDBs WHERE _rowid_ = ?")

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, pk)

	uplinkDB = &UplinkDB{}
	err = obj.driver.QueryRow(__stmt, pk).Scan(&uplinkDB.Publickey, &uplinkDB.Id, &uplinkDB.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return uplinkDB, nil

}

func (impl sqlite3Impl) isConstraintError(err error) (
	constraint string, ok bool) {
	if e, ok := err.(sqlite3.Error); ok {
		if e.Code == sqlite3.ErrConstraint {
			msg := err.Error()
			colon := strings.LastIndex(msg, ":")
			if colon != -1 {
				return strings.TrimSpace(msg[colon:]), true
			}
			return "", true
		}
	}
	return "", false
}

func (obj *sqlite3Impl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.Exec("DELETE FROM project_members;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM users;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM uplinkDBs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM projects;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM overlay_cache_nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM irreparabledbs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM injuredsegments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM bwagreements;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_timestamps;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.Exec("DELETE FROM accounting_raws;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

type Rx struct {
	db *DB
	tx *Tx
}

func (rx *Rx) UnsafeTx(ctx context.Context) (unsafe_tx *sql.Tx, err error) {
	tx, err := rx.getTx(ctx)
	if err != nil {
		return nil, err
	}
	return tx.Tx, nil
}

func (rx *Rx) getTx(ctx context.Context) (tx *Tx, err error) {
	if rx.tx == nil {
		if rx.tx, err = rx.db.Open(ctx); err != nil {
			return nil, err
		}
	}
	return rx.tx, nil
}

func (rx *Rx) Rebind(s string) string {
	return rx.db.Rebind(s)
}

func (rx *Rx) Commit() (err error) {
	if rx.tx != nil {
		err = rx.tx.Commit()
		rx.tx = nil
	}
	return err
}

func (rx *Rx) Rollback() (err error) {
	if rx.tx != nil {
		err = rx.tx.Rollback()
		rx.tx = nil
	}
	return err
}

func (rx *Rx) All_AccountingRaw(ctx context.Context) (
	rows []*AccountingRaw, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_AccountingRaw(ctx)
}

func (rx *Rx) All_AccountingRaw_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	accounting_raw_interval_end_time_greater_or_equal AccountingRaw_IntervalEndTime_Field) (
	rows []*AccountingRaw, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_AccountingRaw_By_IntervalEndTime_GreaterOrEqual(ctx, accounting_raw_interval_end_time_greater_or_equal)
}

func (rx *Rx) All_AccountingRollup_By_StartTime_GreaterOrEqual(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field) (
	rows []*AccountingRollup, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_AccountingRollup_By_StartTime_GreaterOrEqual(ctx, accounting_rollup_start_time_greater_or_equal)
}

func (rx *Rx) All_ApiKey_By_ProjectId_OrderBy_Asc_Name(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	rows []*ApiKey, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_ApiKey_By_ProjectId_OrderBy_Asc_Name(ctx, api_key_project_id)
}

func (rx *Rx) All_Bwagreement(ctx context.Context) (
	rows []*Bwagreement, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Bwagreement(ctx)
}

func (rx *Rx) All_Bwagreement_By_CreatedAt_Greater(ctx context.Context,
	bwagreement_created_at_greater Bwagreement_CreatedAt_Field) (
	rows []*Bwagreement, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Bwagreement_By_CreatedAt_Greater(ctx, bwagreement_created_at_greater)
}

func (rx *Rx) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Node_Id(ctx)
}

func (rx *Rx) All_Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_By_AccountingRollup_StartTime_GreaterOrEqual_And_AccountingRollup_StartTime_Less_OrderBy_Asc_Node_Id(ctx context.Context,
	accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field,
	accounting_rollup_start_time_less AccountingRollup_StartTime_Field) (
	rows []*Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_By_AccountingRollup_StartTime_GreaterOrEqual_And_AccountingRollup_StartTime_Less_OrderBy_Asc_Node_Id(ctx, accounting_rollup_start_time_greater_or_equal, accounting_rollup_start_time_less)
}

func (rx *Rx) All_Project(ctx context.Context) (
	rows []*Project, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Project(ctx)
}

func (rx *Rx) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_ProjectMember_By_MemberId(ctx, project_member_member_id)
}

func (rx *Rx) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx, project_member_member_id)
}

func (rx *Rx) Create_AccountingRaw(ctx context.Context,
	accounting_raw_node_id AccountingRaw_NodeId_Field,
	accounting_raw_interval_end_time AccountingRaw_IntervalEndTime_Field,
	accounting_raw_data_total AccountingRaw_DataTotal_Field,
	accounting_raw_data_type AccountingRaw_DataType_Field) (
	accounting_raw *AccountingRaw, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_AccountingRaw(ctx, accounting_raw_node_id, accounting_raw_interval_end_time, accounting_raw_data_total, accounting_raw_data_type)

}

func (rx *Rx) Create_AccountingRollup(ctx context.Context,
	accounting_rollup_node_id AccountingRollup_NodeId_Field,
	accounting_rollup_start_time AccountingRollup_StartTime_Field,
	accounting_rollup_put_total AccountingRollup_PutTotal_Field,
	accounting_rollup_get_total AccountingRollup_GetTotal_Field,
	accounting_rollup_get_audit_total AccountingRollup_GetAuditTotal_Field,
	accounting_rollup_get_repair_total AccountingRollup_GetRepairTotal_Field,
	accounting_rollup_put_repair_total AccountingRollup_PutRepairTotal_Field,
	accounting_rollup_at_rest_total AccountingRollup_AtRestTotal_Field) (
	accounting_rollup *AccountingRollup, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_AccountingRollup(ctx, accounting_rollup_node_id, accounting_rollup_start_time, accounting_rollup_put_total, accounting_rollup_get_total, accounting_rollup_get_audit_total, accounting_rollup_get_repair_total, accounting_rollup_put_repair_total, accounting_rollup_at_rest_total)

}

func (rx *Rx) Create_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	accounting_timestamps *AccountingTimestamps, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_AccountingTimestamps(ctx, accounting_timestamps_name, accounting_timestamps_value)

}

func (rx *Rx) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_key ApiKey_Key_Field,
	api_key_name ApiKey_Name_Field) (
	api_key *ApiKey, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_ApiKey(ctx, api_key_id, api_key_project_id, api_key_key, api_key_name)

}

func (rx *Rx) Create_Bwagreement(ctx context.Context,
	bwagreement_serialnum Bwagreement_Serialnum_Field,
	bwagreement_storage_node_id Bwagreement_StorageNodeId_Field,
	bwagreement_uplink_id Bwagreement_UplinkId_Field,
	bwagreement_action Bwagreement_Action_Field,
	bwagreement_total Bwagreement_Total_Field,
	bwagreement_expires_at Bwagreement_ExpiresAt_Field) (
	bwagreement *Bwagreement, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_Bwagreement(ctx, bwagreement_serialnum, bwagreement_storage_node_id, bwagreement_uplink_id, bwagreement_action, bwagreement_total, bwagreement_expires_at)

}

func (rx *Rx) Create_Injuredsegment(ctx context.Context,
	injuredsegment_info Injuredsegment_Info_Field) (
	injuredsegment *Injuredsegment, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_Injuredsegment(ctx, injuredsegment_info)

}

func (rx *Rx) Create_Irreparabledb(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	irreparabledb_segmentdetail Irreparabledb_Segmentdetail_Field,
	irreparabledb_pieces_lost_count Irreparabledb_PiecesLostCount_Field,
	irreparabledb_seg_damaged_unix_sec Irreparabledb_SegDamagedUnixSec_Field,
	irreparabledb_repair_attempt_count Irreparabledb_RepairAttemptCount_Field) (
	irreparabledb *Irreparabledb, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_Irreparabledb(ctx, irreparabledb_segmentpath, irreparabledb_segmentdetail, irreparabledb_pieces_lost_count, irreparabledb_seg_damaged_unix_sec, irreparabledb_repair_attempt_count)

}

func (rx *Rx) Create_Node(ctx context.Context,
	node_id Node_Id_Field,
	node_audit_success_count Node_AuditSuccessCount_Field,
	node_total_audit_count Node_TotalAuditCount_Field,
	node_audit_success_ratio Node_AuditSuccessRatio_Field,
	node_uptime_success_count Node_UptimeSuccessCount_Field,
	node_total_uptime_count Node_TotalUptimeCount_Field,
	node_uptime_ratio Node_UptimeRatio_Field) (
	node *Node, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_Node(ctx, node_id, node_audit_success_count, node_total_audit_count, node_audit_success_ratio, node_uptime_success_count, node_total_uptime_count, node_uptime_ratio)

}

func (rx *Rx) Create_OverlayCacheNode(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	overlay_cache_node_node_type OverlayCacheNode_NodeType_Field,
	overlay_cache_node_address OverlayCacheNode_Address_Field,
	overlay_cache_node_protocol OverlayCacheNode_Protocol_Field,
	overlay_cache_node_operator_email OverlayCacheNode_OperatorEmail_Field,
	overlay_cache_node_operator_wallet OverlayCacheNode_OperatorWallet_Field,
	overlay_cache_node_free_bandwidth OverlayCacheNode_FreeBandwidth_Field,
	overlay_cache_node_free_disk OverlayCacheNode_FreeDisk_Field,
	overlay_cache_node_latency_90 OverlayCacheNode_Latency90_Field,
	overlay_cache_node_audit_success_ratio OverlayCacheNode_AuditSuccessRatio_Field,
	overlay_cache_node_audit_uptime_ratio OverlayCacheNode_AuditUptimeRatio_Field,
	overlay_cache_node_audit_count OverlayCacheNode_AuditCount_Field,
	overlay_cache_node_audit_success_count OverlayCacheNode_AuditSuccessCount_Field,
	overlay_cache_node_uptime_count OverlayCacheNode_UptimeCount_Field,
	overlay_cache_node_uptime_success_count OverlayCacheNode_UptimeSuccessCount_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_OverlayCacheNode(ctx, overlay_cache_node_node_id, overlay_cache_node_node_type, overlay_cache_node_address, overlay_cache_node_protocol, overlay_cache_node_operator_email, overlay_cache_node_operator_wallet, overlay_cache_node_free_bandwidth, overlay_cache_node_free_disk, overlay_cache_node_latency_90, overlay_cache_node_audit_success_ratio, overlay_cache_node_audit_uptime_ratio, overlay_cache_node_audit_count, overlay_cache_node_audit_success_count, overlay_cache_node_uptime_count, overlay_cache_node_uptime_success_count)

}

func (rx *Rx) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field) (
	project *Project, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_Project(ctx, project_id, project_name, project_description)

}

func (rx *Rx) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_ProjectMember(ctx, project_member_member_id, project_member_project_id)

}

func (rx *Rx) Create_UplinkDB(ctx context.Context,
	uplinkDB_publickey UplinkDB_Publickey_Field,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_UplinkDB(ctx, uplinkDB_publickey, uplinkDB_id)

}

func (rx *Rx) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_first_name User_FirstName_Field,
	user_last_name User_LastName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Create_User(ctx, user_id, user_first_name, user_last_name, user_password_hash, optional)

}

func (rx *Rx) Delete_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_AccountingRaw_By_Id(ctx, accounting_raw_id)
}

func (rx *Rx) Delete_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_AccountingRollup_By_Id(ctx, accounting_rollup_id)
}

func (rx *Rx) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_ApiKey_By_Id(ctx, api_key_id)
}

func (rx *Rx) Delete_Injuredsegment_By_Id(ctx context.Context,
	injuredsegment_id Injuredsegment_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_Injuredsegment_By_Id(ctx, injuredsegment_id)
}

func (rx *Rx) Delete_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_Irreparabledb_By_Segmentpath(ctx, irreparabledb_segmentpath)
}

func (rx *Rx) Delete_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_Node_By_Id(ctx, node_id)
}

func (rx *Rx) Delete_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_OverlayCacheNode_By_NodeId(ctx, overlay_cache_node_node_id)
}

func (rx *Rx) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_ProjectMember_By_MemberId_And_ProjectId(ctx, project_member_member_id, project_member_project_id)
}

func (rx *Rx) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_Project_By_Id(ctx, project_id)
}

func (rx *Rx) Delete_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_UplinkDB_By_Id(ctx, uplinkDB_id)
}

func (rx *Rx) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Delete_User_By_Id(ctx, user_id)
}

func (rx *Rx) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Find_AccountingTimestamps_Value_By_Name(ctx, accounting_timestamps_name)
}

func (rx *Rx) First_Injuredsegment(ctx context.Context) (
	injuredsegment *Injuredsegment, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.First_Injuredsegment(ctx)
}

func (rx *Rx) Get_AccountingRaw_By_Id(ctx context.Context,
	accounting_raw_id AccountingRaw_Id_Field) (
	accounting_raw *AccountingRaw, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_AccountingRaw_By_Id(ctx, accounting_raw_id)
}

func (rx *Rx) Get_AccountingRollup_By_Id(ctx context.Context,
	accounting_rollup_id AccountingRollup_Id_Field) (
	accounting_rollup *AccountingRollup, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_AccountingRollup_By_Id(ctx, accounting_rollup_id)
}

func (rx *Rx) Get_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	api_key *ApiKey, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_ApiKey_By_Id(ctx, api_key_id)
}

func (rx *Rx) Get_ApiKey_By_Key(ctx context.Context,
	api_key_key ApiKey_Key_Field) (
	api_key *ApiKey, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_ApiKey_By_Key(ctx, api_key_key)
}

func (rx *Rx) Get_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
	irreparabledb *Irreparabledb, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_Irreparabledb_By_Segmentpath(ctx, irreparabledb_segmentpath)
}

func (rx *Rx) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_Node_By_Id(ctx, node_id)
}

func (rx *Rx) Get_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	overlay_cache_node *OverlayCacheNode, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_OverlayCacheNode_By_NodeId(ctx, overlay_cache_node_node_id)
}

func (rx *Rx) Get_OverlayCacheNode_OperatorWallet_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
	row *OperatorWallet_Row, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_OverlayCacheNode_OperatorWallet_By_NodeId(ctx, overlay_cache_node_node_id)
}

func (rx *Rx) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_Project_By_Id(ctx, project_id)
}

func (rx *Rx) Get_UplinkDB_By_Id(ctx context.Context,
	uplinkDB_id UplinkDB_Id_Field) (
	uplinkDB *UplinkDB, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_UplinkDB_By_Id(ctx, uplinkDB_id)
}

func (rx *Rx) Get_User_By_Email(ctx context.Context,
	user_email User_Email_Field) (
	user *User, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_User_By_Email(ctx, user_email)
}

func (rx *Rx) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Get_User_By_Id(ctx, user_id)
}

func (rx *Rx) Limited_Bwagreement(ctx context.Context,
	limit int, offset int64) (
	rows []*Bwagreement, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Limited_Bwagreement(ctx, limit, offset)
}

func (rx *Rx) Limited_Injuredsegment(ctx context.Context,
	limit int, offset int64) (
	rows []*Injuredsegment, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Limited_Injuredsegment(ctx, limit, offset)
}

func (rx *Rx) Limited_OverlayCacheNode_By_NodeId_GreaterOrEqual(ctx context.Context,
	overlay_cache_node_node_id_greater_or_equal OverlayCacheNode_NodeId_Field,
	limit int, offset int64) (
	rows []*OverlayCacheNode, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Limited_OverlayCacheNode_By_NodeId_GreaterOrEqual(ctx, overlay_cache_node_node_id_greater_or_equal, limit, offset)
}

func (rx *Rx) Limited_ProjectMember_By_ProjectId(ctx context.Context,
	project_member_project_id ProjectMember_ProjectId_Field,
	limit int, offset int64) (
	rows []*ProjectMember, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Limited_ProjectMember_By_ProjectId(ctx, project_member_project_id, limit, offset)
}

func (rx *Rx) Update_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	accounting_timestamps *AccountingTimestamps, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_AccountingTimestamps_By_Name(ctx, accounting_timestamps_name, update)
}

func (rx *Rx) Update_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	api_key *ApiKey, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_ApiKey_By_Id(ctx, api_key_id, update)
}

func (rx *Rx) Update_Irreparabledb_By_Segmentpath(ctx context.Context,
	irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
	update Irreparabledb_Update_Fields) (
	irreparabledb *Irreparabledb, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_Irreparabledb_By_Segmentpath(ctx, irreparabledb_segmentpath, update)
}

func (rx *Rx) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_Node_By_Id(ctx, node_id, update)
}

func (rx *Rx) Update_OverlayCacheNode_By_NodeId(ctx context.Context,
	overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
	update OverlayCacheNode_Update_Fields) (
	overlay_cache_node *OverlayCacheNode, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_OverlayCacheNode_By_NodeId(ctx, overlay_cache_node_node_id, update)
}

func (rx *Rx) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_Project_By_Id(ctx, project_id, update)
}

func (rx *Rx) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	var tx *Tx
	if tx, err = rx.getTx(ctx); err != nil {
		return
	}
	return tx.Update_User_By_Id(ctx, user_id, update)
}

type Methods interface {
	All_AccountingRaw(ctx context.Context) (
		rows []*AccountingRaw, err error)

	All_AccountingRaw_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
		accounting_raw_interval_end_time_greater_or_equal AccountingRaw_IntervalEndTime_Field) (
		rows []*AccountingRaw, err error)

	All_AccountingRollup_By_StartTime_GreaterOrEqual(ctx context.Context,
		accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field) (
		rows []*AccountingRollup, err error)

	All_ApiKey_By_ProjectId_OrderBy_Asc_Name(ctx context.Context,
		api_key_project_id ApiKey_ProjectId_Field) (
		rows []*ApiKey, err error)

	All_Bwagreement(ctx context.Context) (
		rows []*Bwagreement, err error)

	All_Bwagreement_By_CreatedAt_Greater(ctx context.Context,
		bwagreement_created_at_greater Bwagreement_CreatedAt_Field) (
		rows []*Bwagreement, err error)

	All_Node_Id(ctx context.Context) (
		rows []*Id_Row, err error)

	All_Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_By_AccountingRollup_StartTime_GreaterOrEqual_And_AccountingRollup_StartTime_Less_OrderBy_Asc_Node_Id(ctx context.Context,
		accounting_rollup_start_time_greater_or_equal AccountingRollup_StartTime_Field,
		accounting_rollup_start_time_less AccountingRollup_StartTime_Field) (
		rows []*Node_Id_Node_CreatedAt_Node_AuditSuccessRatio_AccountingRollup_StartTime_AccountingRollup_PutTotal_AccountingRollup_GetTotal_AccountingRollup_GetAuditTotal_AccountingRollup_GetRepairTotal_AccountingRollup_PutRepairTotal_AccountingRollup_AtRestTotal_Row, err error)

	All_Project(ctx context.Context) (
		rows []*Project, err error)

	All_ProjectMember_By_MemberId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field) (
		rows []*ProjectMember, err error)

	All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field) (
		rows []*Project, err error)

	Create_AccountingRaw(ctx context.Context,
		accounting_raw_node_id AccountingRaw_NodeId_Field,
		accounting_raw_interval_end_time AccountingRaw_IntervalEndTime_Field,
		accounting_raw_data_total AccountingRaw_DataTotal_Field,
		accounting_raw_data_type AccountingRaw_DataType_Field) (
		accounting_raw *AccountingRaw, err error)

	Create_AccountingRollup(ctx context.Context,
		accounting_rollup_node_id AccountingRollup_NodeId_Field,
		accounting_rollup_start_time AccountingRollup_StartTime_Field,
		accounting_rollup_put_total AccountingRollup_PutTotal_Field,
		accounting_rollup_get_total AccountingRollup_GetTotal_Field,
		accounting_rollup_get_audit_total AccountingRollup_GetAuditTotal_Field,
		accounting_rollup_get_repair_total AccountingRollup_GetRepairTotal_Field,
		accounting_rollup_put_repair_total AccountingRollup_PutRepairTotal_Field,
		accounting_rollup_at_rest_total AccountingRollup_AtRestTotal_Field) (
		accounting_rollup *AccountingRollup, err error)

	Create_AccountingTimestamps(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field,
		accounting_timestamps_value AccountingTimestamps_Value_Field) (
		accounting_timestamps *AccountingTimestamps, err error)

	Create_ApiKey(ctx context.Context,
		api_key_id ApiKey_Id_Field,
		api_key_project_id ApiKey_ProjectId_Field,
		api_key_key ApiKey_Key_Field,
		api_key_name ApiKey_Name_Field) (
		api_key *ApiKey, err error)

	Create_Bwagreement(ctx context.Context,
		bwagreement_serialnum Bwagreement_Serialnum_Field,
		bwagreement_storage_node_id Bwagreement_StorageNodeId_Field,
		bwagreement_uplink_id Bwagreement_UplinkId_Field,
		bwagreement_action Bwagreement_Action_Field,
		bwagreement_total Bwagreement_Total_Field,
		bwagreement_expires_at Bwagreement_ExpiresAt_Field) (
		bwagreement *Bwagreement, err error)

	Create_Injuredsegment(ctx context.Context,
		injuredsegment_info Injuredsegment_Info_Field) (
		injuredsegment *Injuredsegment, err error)

	Create_Irreparabledb(ctx context.Context,
		irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
		irreparabledb_segmentdetail Irreparabledb_Segmentdetail_Field,
		irreparabledb_pieces_lost_count Irreparabledb_PiecesLostCount_Field,
		irreparabledb_seg_damaged_unix_sec Irreparabledb_SegDamagedUnixSec_Field,
		irreparabledb_repair_attempt_count Irreparabledb_RepairAttemptCount_Field) (
		irreparabledb *Irreparabledb, err error)

	Create_Node(ctx context.Context,
		node_id Node_Id_Field,
		node_audit_success_count Node_AuditSuccessCount_Field,
		node_total_audit_count Node_TotalAuditCount_Field,
		node_audit_success_ratio Node_AuditSuccessRatio_Field,
		node_uptime_success_count Node_UptimeSuccessCount_Field,
		node_total_uptime_count Node_TotalUptimeCount_Field,
		node_uptime_ratio Node_UptimeRatio_Field) (
		node *Node, err error)

	Create_OverlayCacheNode(ctx context.Context,
		overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
		overlay_cache_node_node_type OverlayCacheNode_NodeType_Field,
		overlay_cache_node_address OverlayCacheNode_Address_Field,
		overlay_cache_node_protocol OverlayCacheNode_Protocol_Field,
		overlay_cache_node_operator_email OverlayCacheNode_OperatorEmail_Field,
		overlay_cache_node_operator_wallet OverlayCacheNode_OperatorWallet_Field,
		overlay_cache_node_free_bandwidth OverlayCacheNode_FreeBandwidth_Field,
		overlay_cache_node_free_disk OverlayCacheNode_FreeDisk_Field,
		overlay_cache_node_latency_90 OverlayCacheNode_Latency90_Field,
		overlay_cache_node_audit_success_ratio OverlayCacheNode_AuditSuccessRatio_Field,
		overlay_cache_node_audit_uptime_ratio OverlayCacheNode_AuditUptimeRatio_Field,
		overlay_cache_node_audit_count OverlayCacheNode_AuditCount_Field,
		overlay_cache_node_audit_success_count OverlayCacheNode_AuditSuccessCount_Field,
		overlay_cache_node_uptime_count OverlayCacheNode_UptimeCount_Field,
		overlay_cache_node_uptime_success_count OverlayCacheNode_UptimeSuccessCount_Field) (
		overlay_cache_node *OverlayCacheNode, err error)

	Create_Project(ctx context.Context,
		project_id Project_Id_Field,
		project_name Project_Name_Field,
		project_description Project_Description_Field) (
		project *Project, err error)

	Create_ProjectMember(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field) (
		project_member *ProjectMember, err error)

	Create_UplinkDB(ctx context.Context,
		uplinkDB_publickey UplinkDB_Publickey_Field,
		uplinkDB_id UplinkDB_Id_Field) (
		uplinkDB *UplinkDB, err error)

	Create_User(ctx context.Context,
		user_id User_Id_Field,
		user_first_name User_FirstName_Field,
		user_last_name User_LastName_Field,
		user_password_hash User_PasswordHash_Field,
		optional User_Create_Fields) (
		user *User, err error)

	Delete_AccountingRaw_By_Id(ctx context.Context,
		accounting_raw_id AccountingRaw_Id_Field) (
		deleted bool, err error)

	Delete_AccountingRollup_By_Id(ctx context.Context,
		accounting_rollup_id AccountingRollup_Id_Field) (
		deleted bool, err error)

	Delete_ApiKey_By_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field) (
		deleted bool, err error)

	Delete_Injuredsegment_By_Id(ctx context.Context,
		injuredsegment_id Injuredsegment_Id_Field) (
		deleted bool, err error)

	Delete_Irreparabledb_By_Segmentpath(ctx context.Context,
		irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
		deleted bool, err error)

	Delete_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field) (
		deleted bool, err error)

	Delete_OverlayCacheNode_By_NodeId(ctx context.Context,
		overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
		deleted bool, err error)

	Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field) (
		deleted bool, err error)

	Delete_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		deleted bool, err error)

	Delete_UplinkDB_By_Id(ctx context.Context,
		uplinkDB_id UplinkDB_Id_Field) (
		deleted bool, err error)

	Delete_User_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		deleted bool, err error)

	Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field) (
		row *Value_Row, err error)

	First_Injuredsegment(ctx context.Context) (
		injuredsegment *Injuredsegment, err error)

	Get_AccountingRaw_By_Id(ctx context.Context,
		accounting_raw_id AccountingRaw_Id_Field) (
		accounting_raw *AccountingRaw, err error)

	Get_AccountingRollup_By_Id(ctx context.Context,
		accounting_rollup_id AccountingRollup_Id_Field) (
		accounting_rollup *AccountingRollup, err error)

	Get_ApiKey_By_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field) (
		api_key *ApiKey, err error)

	Get_ApiKey_By_Key(ctx context.Context,
		api_key_key ApiKey_Key_Field) (
		api_key *ApiKey, err error)

	Get_Irreparabledb_By_Segmentpath(ctx context.Context,
		irreparabledb_segmentpath Irreparabledb_Segmentpath_Field) (
		irreparabledb *Irreparabledb, err error)

	Get_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field) (
		node *Node, err error)

	Get_OverlayCacheNode_By_NodeId(ctx context.Context,
		overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
		overlay_cache_node *OverlayCacheNode, err error)

	Get_OverlayCacheNode_OperatorWallet_By_NodeId(ctx context.Context,
		overlay_cache_node_node_id OverlayCacheNode_NodeId_Field) (
		row *OperatorWallet_Row, err error)

	Get_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		project *Project, err error)

	Get_UplinkDB_By_Id(ctx context.Context,
		uplinkDB_id UplinkDB_Id_Field) (
		uplinkDB *UplinkDB, err error)

	Get_User_By_Email(ctx context.Context,
		user_email User_Email_Field) (
		user *User, err error)

	Get_User_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		user *User, err error)

	Limited_Bwagreement(ctx context.Context,
		limit int, offset int64) (
		rows []*Bwagreement, err error)

	Limited_Injuredsegment(ctx context.Context,
		limit int, offset int64) (
		rows []*Injuredsegment, err error)

	Limited_OverlayCacheNode_By_NodeId_GreaterOrEqual(ctx context.Context,
		overlay_cache_node_node_id_greater_or_equal OverlayCacheNode_NodeId_Field,
		limit int, offset int64) (
		rows []*OverlayCacheNode, err error)

	Limited_ProjectMember_By_ProjectId(ctx context.Context,
		project_member_project_id ProjectMember_ProjectId_Field,
		limit int, offset int64) (
		rows []*ProjectMember, err error)

	Update_AccountingTimestamps_By_Name(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field,
		update AccountingTimestamps_Update_Fields) (
		accounting_timestamps *AccountingTimestamps, err error)

	Update_ApiKey_By_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field,
		update ApiKey_Update_Fields) (
		api_key *ApiKey, err error)

	Update_Irreparabledb_By_Segmentpath(ctx context.Context,
		irreparabledb_segmentpath Irreparabledb_Segmentpath_Field,
		update Irreparabledb_Update_Fields) (
		irreparabledb *Irreparabledb, err error)

	Update_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field,
		update Node_Update_Fields) (
		node *Node, err error)

	Update_OverlayCacheNode_By_NodeId(ctx context.Context,
		overlay_cache_node_node_id OverlayCacheNode_NodeId_Field,
		update OverlayCacheNode_Update_Fields) (
		overlay_cache_node *OverlayCacheNode, err error)

	Update_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field,
		update Project_Update_Fields) (
		project *Project, err error)

	Update_User_By_Id(ctx context.Context,
		user_id User_Id_Field,
		update User_Update_Fields) (
		user *User, err error)
}

type TxMethods interface {
	Methods

	Rebind(s string) string
	Commit() error
	Rollback() error
}

type txMethods interface {
	TxMethods

	deleteAll(ctx context.Context) (int64, error)
	makeErr(err error) error
}

type DBMethods interface {
	Methods

	Schema() string
	Rebind(sql string) string
}

type dbMethods interface {
	DBMethods

	wrapTx(tx *sql.Tx) txMethods
	makeErr(err error) error
}

func openpostgres(source string) (*sql.DB, error) {
	return sql.Open("postgres", source)
}

var sqlite3DriverName = func() string {
	var id [16]byte
	rand.Read(id[:])
	return fmt.Sprintf("sqlite3_%x", string(id[:]))
}()

func init() {
	sql.Register(sqlite3DriverName, &sqlite3.SQLiteDriver{
		ConnectHook: sqlite3SetupConn,
	})
}

// SQLite3JournalMode controls the journal_mode pragma for all new connections.
// Since it is read without a mutex, it must be changed to the value you want
// before any Open calls.
var SQLite3JournalMode = "WAL"

func sqlite3SetupConn(conn *sqlite3.SQLiteConn) (err error) {
	_, err = conn.Exec("PRAGMA foreign_keys = ON", nil)
	if err != nil {
		return makeErr(err)
	}
	_, err = conn.Exec("PRAGMA journal_mode = "+SQLite3JournalMode, nil)
	if err != nil {
		return makeErr(err)
	}
	return nil
}

func opensqlite3(source string) (*sql.DB, error) {
	return sql.Open(sqlite3DriverName, source)
}
